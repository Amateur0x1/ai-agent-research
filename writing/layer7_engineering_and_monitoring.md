# ç¬¬ä¸ƒå±‚ï¼šå·¥ç¨‹åŒ–ä¸å®¹é”™ç›‘æ§å±‚ - æŠ€æœ¯å®ç°è¯¦è§£

## æ¦‚è¿°

å·¥ç¨‹åŒ–ä¸å®¹é”™ç›‘æ§å±‚æ˜¯ç¡®ä¿ AI Agent ç³»ç»Ÿåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šè¿è¡Œçš„æœ€åä¸€é“é˜²çº¿ã€‚è¯¥å±‚å…³æ³¨ä¸‰ä¸ªæ ¸å¿ƒèƒ½åŠ›ï¼š

1. **æ™ºèƒ½å®¹é”™** - é”™è¯¯æ£€æµ‹ã€æ™ºèƒ½åæ€ã€è‡ªåŠ¨é‡è¯•ä¸é™çº§
2. **å¯è§‚æµ‹æ€§** - å®Œæ•´çš„è¿½è¸ªã€ç›‘æ§ä¸æ€§èƒ½åˆ†æ
3. **æ•…éšœæ¢å¤** - æ£€æŸ¥ç‚¹å›é€€ã€æ—¶é—´æ—…è¡Œä¸çŠ¶æ€é‡æ”¾

æœ¬æ–‡é€šè¿‡ **MathModelAgent**ï¼ˆæ™ºèƒ½é‡è¯•ï¼‰ã€**ADK**ï¼ˆOpenTelemetry è¿½è¸ªï¼‰ã€**OpenAI Agents SDK**ï¼ˆè‡ªåŠ¨è¿½è¸ªï¼‰ã€**LangGraph**ï¼ˆæ—¶é—´æ—…è¡Œï¼‰çš„çœŸå®ä»£ç ï¼Œå±•ç¤ºç”Ÿäº§çº§ Agent ç³»ç»Ÿçš„å·¥ç¨‹åŒ–å®è·µã€‚

## æ ¸å¿ƒèŒè´£

1. **é”™è¯¯å¤„ç†ä¸é‡è¯•** - æ™ºèƒ½è¯†åˆ«é”™è¯¯å¹¶è‡ªåŠ¨ä¿®å¤
2. **æ‰§è¡Œè¿½è¸ª** - è®°å½•å®Œæ•´çš„æ‰§è¡Œè½¨è¿¹
3. **æ€§èƒ½ç›‘æ§** - Token ä½¿ç”¨ã€å»¶è¿Ÿã€æˆæœ¬åˆ†æ
4. **æ•…éšœæ¢å¤** - ä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œ
5. **å¯è§‚æµ‹æ€§** - é›†æˆå¤–éƒ¨ç›‘æ§å¹³å°

---

## ä¸€ã€æ™ºèƒ½å®¹é”™ï¼šé”™è¯¯åæ€ä¸è‡ªåŠ¨é‡è¯•

### 1.1 MathModelAgentï¼šCoderAgent çš„æ™ºèƒ½é‡è¯•æœºåˆ¶

CoderAgent å®ç°äº†æœ€æœ‰ä»£è¡¨æ€§çš„æ™ºèƒ½å®¹é”™æ¨¡å¼ï¼š**é”™è¯¯æ£€æµ‹ â†’ åæ€åˆ†æ â†’ é‡æ–°ç”Ÿæˆä»£ç **ã€‚

```python
# MathModelAgent/backend/app/core/agents/coder_agent.py
class CoderAgent(Agent):
    def __init__(
        self,
        task_id: str,
        model: LLM,
        work_dir: str,
        max_chat_turns: int = settings.MAX_CHAT_TURNS,
        max_retries: int = settings.MAX_RETRIES,  # æœ€å¤§åæ€æ¬¡æ•°
        code_interpreter: BaseCodeInterpreter = None,
    ):
        super().__init__(task_id, model, max_chat_turns)
        self.work_dir = work_dir
        self.max_retries = max_retries
        self.code_interpreter = code_interpreter
    
    async def run(self, prompt: str, subtask_title: str) -> CoderToWriter:
        retry_count = 0
        last_error_message = None
        
        while retry_count < self.max_retries:
            # è°ƒç”¨ LLM ç”Ÿæˆä»£ç 
            response = await self.model.chat(
                history=self.chat_history,
                tools=coder_tools,
                tool_choice="auto"
            )
            
            # æ£€æµ‹å·¥å…·è°ƒç”¨
            tool_calls = response.choices[0].message.tool_calls
            if tool_calls:
                for tool_call in tool_calls:
                    tool_id = tool_call.id
                    code = json.loads(tool_call.function.arguments)["code"]
                    
                    # æ‰§è¡Œä»£ç 
                    (
                        text_to_gpt,
                        error_occurred,
                        error_message,
                    ) = await self.code_interpreter.execute_code(code)
                    
                    if error_occurred:
                        # è®°å½•é”™è¯¯å·¥å…·å“åº”
                        await self.append_chat_history({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": "execute_code",
                            "content": error_message,
                        })
                        
                        # å¢åŠ é‡è¯•è®¡æ•°
                        logger.warning(f"ä»£ç æ‰§è¡Œé”™è¯¯: {error_message}")
                        retry_count += 1
                        logger.info(f"å½“å‰å°è¯•æ¬¡æ•°: {retry_count} / {self.max_retries}")
                        
                        # === æ ¸å¿ƒï¼šç”Ÿæˆåæ€æç¤º ===
                        reflection_prompt = get_reflection_prompt(error_message, code)
                        
                        await redis_manager.publish_message(
                            self.task_id,
                            SystemMessage(content="ä»£ç æ‰‹åæ€çº æ­£é”™è¯¯", type="error"),
                        )
                        
                        # å°†åæ€æç¤ºæ·»åŠ åˆ°å¯¹è¯å†å²
                        await self.append_chat_history({
                            "role": "user",
                            "content": reflection_prompt
                        })
                        
                        # ç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯ï¼Œè®© LLM é‡æ–°ç”Ÿæˆä»£ç 
                        continue
                    else:
                        # æˆåŠŸæ‰§è¡Œ
                        await self.append_chat_history({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": "execute_code",
                            "content": text_to_gpt,
                        })
                        return CoderToWriter(code_response=text_to_gpt, ...)
```

**è®¾è®¡äº®ç‚¹ï¼š**
- **æ™ºèƒ½åæ€**ï¼šä¸æ˜¯ç®€å•é‡è¯•ï¼Œè€Œæ˜¯é€šè¿‡ LLM åˆ†æé”™è¯¯åŸå› 
- **ä¸Šä¸‹æ–‡ç´¯ç§¯**ï¼šé”™è¯¯ä¿¡æ¯ä¿ç•™åœ¨å¯¹è¯å†å²ä¸­ï¼Œå¸®åŠ© LLM å­¦ä¹ 
- **åˆ†å±‚é‡è¯•**ï¼šAgent çº§åˆ«çš„é‡è¯•æ¬¡æ•°ç‹¬ç«‹äº LLM è°ƒç”¨çš„é‡è¯•

### 1.2 åæ€æç¤ºçš„è®¾è®¡

```python
# MathModelAgent/backend/app/core/prompts.py
def get_reflection_prompt(error_message, code) -> str:
    return f"""The code execution encountered an error:
{error_message}

Please analyze the error, identify the cause, and provide a corrected version of the code. 
Consider:
1. Syntax errors
2. Missing imports
3. Incorrect variable names or types
4. File path issues
5. Any other potential issues
6. If a task repeatedly fails to complete, try breaking down the code, changing your approach, or simplifying the model.
7. Don't ask user any thing about how to do and next to do, just do it by yourself.

Previous code:
{code}

Please provide an explanation of what went wrong and Remember call the function tools to retry
"""
```

**å…³é”®è¦ç´ ï¼š**
- **é”™è¯¯ä¸Šä¸‹æ–‡**ï¼šåŒ…å«å®Œæ•´çš„é”™è¯¯æ¶ˆæ¯å’Œå¤±è´¥ä»£ç 
- **å¼•å¯¼æ€è€ƒ**ï¼šæç¤º LLM ä»å¤šä¸ªè§’åº¦åˆ†æé—®é¢˜
- **è¡ŒåŠ¨æŒ‡ä»¤**ï¼šæ˜ç¡®è¦æ±‚ç”Ÿæˆä¿®æ­£ä»£ç å¹¶é‡æ–°è°ƒç”¨å·¥å…·

### 1.3 LLM å±‚çš„æŒ‡æ•°é€€é¿é‡è¯•

```python
# MathModelAgent/backend/app/core/llm/llm.py
class LLM:
    async def chat(
        self,
        history: list = None,
        tools: list = None,
        max_retries: int = 8,      # æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: float = 1.0,  # åˆå§‹é‡è¯•å»¶è¿Ÿ
        **kwargs
    ) -> str:
        # éªŒè¯å·¥å…·è°ƒç”¨å®Œæ•´æ€§
        if history:
            history = self._validate_and_fix_tool_calls(history)
        
        # æŒ‡æ•°é€€é¿é‡è¯•
        for attempt in range(max_retries):
            try:
                response = await acompletion(**kwargs)
                
                if not response or not hasattr(response, "choices"):
                    raise ValueError("æ— æ•ˆçš„APIå“åº”")
                
                self.chat_count += 1
                await self.send_message(response, agent_name, sub_title)
                return response
                
            except Exception as e:
                logger.error(f"ç¬¬{attempt + 1}æ¬¡é‡è¯•: {str(e)}")
                
                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿ï¼šå»¶è¿Ÿæ—¶é—´éšé‡è¯•æ¬¡æ•°å¢åŠ 
                    time.sleep(retry_delay * (attempt + 1))
                    continue
                
                # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                logger.debug(f"è¯·æ±‚å‚æ•°: {kwargs}")
                raise
```

**è®¾è®¡ä¼˜åŠ¿ï¼š**
- **åŒå±‚é˜²æŠ¤**ï¼šAgent çº§é‡è¯•ï¼ˆæ™ºèƒ½ï¼‰+ LLM è°ƒç”¨é‡è¯•ï¼ˆç½‘ç»œï¼‰
- **æŒ‡æ•°é€€é¿**ï¼šé¿å…å¯¹ API é€ æˆå‹åŠ›
- **å®Œæ•´æ€§éªŒè¯**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤å·¥å…·è°ƒç”¨åºåˆ—

### 1.4 JSON è§£æçš„å®¹é”™é‡è¯•

```python
# MathModelAgent/backend/app/core/agents/coordinator_agent.py
class CoordinatorAgent(Agent):
    async def run(self, ques_all: str) -> CoordinatorToModeler:
        max_retries = 3
        attempt = 0
        
        while attempt <= max_retries:
            try:
                response = await self.model.chat(
                    history=self.chat_history,
                    agent_name=self.__class__.__name__,
                )
                
                json_str = response.choices[0].message.content
                
                # æ¸…ç† JSON å­—ç¬¦ä¸²
                json_str = json_str.replace("```json", "").replace("```", "").strip()
                json_str = re.sub(r"[\x00-\x1F\x7F]", "", json_str)
                
                if not json_str:
                    raise ValueError("è¿”å›çš„ JSON å­—ç¬¦ä¸²ä¸ºç©º")
                
                questions = json.loads(json_str)
                ques_count = questions["ques_count"]
                
                logger.info(f"questions:{questions}")
                return CoordinatorToModeler(questions=questions, ques_count=ques_count)
                
            except (json.JSONDecodeError, ValueError, KeyError) as e:
                attempt += 1
                logger.warning(f"è§£æå¤±è´¥ (å°è¯• {attempt}/{max_retries}): {str(e)}")
                
                if attempt > max_retries:
                    logger.error(f"è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè§£æ")
                    raise RuntimeError(f"æ— æ³•è§£ææ¨¡å‹å“åº”: {str(e)}")
                
                # æ·»åŠ é”™è¯¯åé¦ˆæç¤º
                error_prompt = f"âš ï¸ ä¸Šæ¬¡å“åº”æ ¼å¼é”™è¯¯: {str(e)}ã€‚è¯·ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼"
                await self.append_chat_history({
                    "role": "system",
                    "content": self.system_prompt + "\n" + error_prompt
                })
        
        raise RuntimeError("æ„å¤–çš„æµç¨‹ç»ˆæ­¢")
```

**å…³é”®ç­–ç•¥ï¼š**
- **ä¸»åŠ¨æ¸…ç†**ï¼šå»é™¤ Markdown ä»£ç å—æ ‡è®°
- **å³æ—¶åé¦ˆ**ï¼šå°†è§£æé”™è¯¯åé¦ˆç»™ LLM
- **æ˜ç¡®è¾¹ç•Œ**ï¼šè¶…è¿‡é‡è¯•æ¬¡æ•°åæ˜ç¡®å¤±è´¥

---

## äºŒã€å¯è§‚æµ‹æ€§ï¼šOpenTelemetry è¿½è¸ªï¼ˆADKï¼‰

### 2.1 ADK çš„è‡ªåŠ¨è¿½è¸ªæ¶æ„

ADK å†…ç½®äº†å®Œæ•´çš„ OpenTelemetry è¿½è¸ªï¼Œè‡ªåŠ¨è®°å½•æ™ºèƒ½ä½“æ‰§è¡Œã€å·¥å…·è°ƒç”¨ã€LLM è¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯ã€‚

```python
# adk-python/src/google/adk/agents/base_agent.py
class BaseAgent(BaseModel):
    async def run_async(
        self,
        parent_context: InvocationContext,
    ) -> AsyncGenerator[Event, None]:
        """æ™ºèƒ½ä½“è¿è¡Œå…¥å£ï¼Œè‡ªåŠ¨åŒ…è£…è¿½è¸ª"""
        
        async def _run_with_trace() -> AsyncGenerator[Event, None]:
            # åˆ›å»ºè¿½è¸ª Span
            with tracer.start_as_current_span(f'invoke_agent {self.name}') as span:
                ctx = self._create_invocation_context(parent_context)
                
                # è®°å½•æ™ºèƒ½ä½“è°ƒç”¨ä¿¡æ¯
                tracing.trace_agent_invocation(span, self, ctx)
                
                # å‰ç½®å›è°ƒ
                if event := await self.__handle_before_agent_callback(ctx):
                    yield event
                
                if ctx.end_invocation:
                    return
                
                # æ‰§è¡Œæ™ºèƒ½ä½“é€»è¾‘
                async with Aclosing(self._run_async_impl(ctx)) as agen:
                    async for event in agen:
                        yield event
                
                if ctx.end_invocation:
                    return
                
                # åç½®å›è°ƒ
                if event := await self.__handle_after_agent_callback(ctx):
                    yield event
        
        async with Aclosing(_run_with_trace()) as agen:
            async for event in agen:
                yield event
```

### 2.2 æ™ºèƒ½ä½“è°ƒç”¨è¿½è¸ª

```python
# adk-python/src/google/adk/telemetry/tracing.py
def trace_agent_invocation(
    span: trace.Span, agent: BaseAgent, ctx: InvocationContext
) -> None:
    """è®°å½•æ™ºèƒ½ä½“è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯"""
    
    # å¿…éœ€å±æ€§
    span.set_attribute('gen_ai.operation.name', 'invoke_agent')
    
    # æ™ºèƒ½ä½“ä¿¡æ¯
    span.set_attribute('gen_ai.agent.description', agent.description)
    span.set_attribute('gen_ai.agent.name', agent.name)
    
    # ä¼šè¯ä¿¡æ¯
    span.set_attribute('gen_ai.conversation.id', ctx.session.id)
```

### 2.3 å·¥å…·è°ƒç”¨è¿½è¸ª

```python
# adk-python/src/google/adk/telemetry/tracing.py
def trace_tool_call(
    tool: BaseTool,
    args: dict[str, Any],
    function_response_event: Event,
):
    """è®°å½•å·¥å…·è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯"""
    span = trace.get_current_span()
    
    # å·¥å…·å…ƒä¿¡æ¯
    span.set_attribute('gen_ai.operation.name', 'execute_tool')
    span.set_attribute('gen_ai.tool.description', tool.description)
    span.set_attribute('gen_ai.tool.name', tool.name)
    span.set_attribute('gen_ai.tool.type', tool.__class__.__name__)
    
    # å·¥å…·è°ƒç”¨å‚æ•°
    span.set_attribute(
        'gcp.vertex.agent.tool_call_args',
        _safe_json_serialize(args),
    )
    
    # å·¥å…·å“åº”
    tool_call_id = '<not specified>'
    tool_response = '<not specified>'
    
    if function_response_event.content and function_response_event.content.parts:
        response_parts = function_response_event.content.parts
        function_response = response_parts[0].function_response
        
        if function_response:
            if function_response.id:
                tool_call_id = function_response.id
            if function_response.response:
                tool_response = function_response.response
    
    span.set_attribute('gen_ai.tool.call_id', tool_call_id)
    
    if not isinstance(tool_response, dict):
        tool_response = {'result': tool_response}
    
    span.set_attribute(
        'gcp.vertex.agent.tool_response',
        _safe_json_serialize(tool_response),
    )
```

### 2.4 LLM è°ƒç”¨è¿½è¸ª

```python
# adk-python/src/google/adk/telemetry/tracing.py
def trace_call_llm(
    invocation_context: InvocationContext,
    event_id: str,
    llm_request: LlmRequest,
    llm_response: LlmResponse,
):
    """è®°å½• LLM è°ƒç”¨çš„å®Œæ•´ä¿¡æ¯"""
    span = trace.get_current_span()
    
    # æ ‡å‡† GenAI å±æ€§
    span.set_attribute('gen_ai.system', 'gcp.vertex.agent')
    span.set_attribute('gen_ai.request.model', llm_request.model)
    
    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    span.set_attribute('gcp.vertex.agent.invocation_id', invocation_context.invocation_id)
    span.set_attribute('gcp.vertex.agent.session_id', invocation_context.session.id)
    span.set_attribute('gcp.vertex.agent.event_id', event_id)
    
    # è¯·æ±‚å‚æ•°
    span.set_attribute(
        'gcp.vertex.agent.llm_request',
        _safe_json_serialize(_build_llm_request_for_trace(llm_request)),
    )
    
    # é…ç½®å‚æ•°
    if llm_request.config:
        if llm_request.config.top_p:
            span.set_attribute('gen_ai.request.top_p', llm_request.config.top_p)
        if llm_request.config.max_output_tokens:
            span.set_attribute('gen_ai.request.max_tokens', llm_request.config.max_output_tokens)
    
    # å“åº”ä¿¡æ¯
    try:
        llm_response_json = llm_response.model_dump_json(exclude_none=True)
    except Exception:
        llm_response_json = '<not serializable>'
    
    span.set_attribute('gcp.vertex.agent.llm_response', llm_response_json)
    
    # Token ä½¿ç”¨ç»Ÿè®¡
    if llm_response.usage_metadata:
        span.set_attribute('gen_ai.usage.input_tokens', llm_response.usage_metadata.prompt_tokens)
        span.set_attribute('gen_ai.usage.output_tokens', llm_response.usage_metadata.candidates_tokens)
```

**è¿½è¸ªä½“ç³»ä¼˜åŠ¿ï¼š**
- **å®Œæ•´è¦†ç›–**ï¼šAgentã€Toolã€LLM ä¸‰å±‚å…¨è¦†ç›–
- **æ ‡å‡†åŒ–**ï¼šéµå¾ª OpenTelemetry GenAI è¯­ä¹‰çº¦å®š
- **å¯æ‰©å±•**ï¼šæ”¯æŒè‡ªå®šä¹‰å¯¼å‡ºå™¨ï¼ˆLogfireã€AgentOps ç­‰ï¼‰
- **é›¶ä¾µå…¥**ï¼šè‡ªåŠ¨è¿½è¸ªï¼Œæ— éœ€æ‰‹åŠ¨åŸ‹ç‚¹

---

## ä¸‰ã€OpenAI Agents SDKï¼šè‡ªåŠ¨è¿½è¸ªä¸ Span ç®¡ç†

### 3.1 é»˜è®¤è¿½è¸ªæœºåˆ¶

OpenAI Agents SDK å†…ç½®äº†å…¨é¢çš„è¿½è¸ªç³»ç»Ÿï¼Œé»˜è®¤å¼€å¯ï¼š

```python
# openai-agents-python-main/docs/tracing.mdï¼ˆæ‘˜è¦ï¼‰
# é»˜è®¤è¿½è¸ªçš„å†…å®¹ï¼š
# 1. æ•´ä¸ª Runner.{run, run_sync, run_streamed}() è¢«åŒ…è£…åœ¨ trace() ä¸­
# 2. æ¯æ¬¡ Agent æ‰§è¡Œè¢«åŒ…è£…åœ¨ agent_span() ä¸­
# 3. LLM ç”Ÿæˆè¢«åŒ…è£…åœ¨ generation_span() ä¸­
# 4. å‡½æ•°å·¥å…·è°ƒç”¨è¢«åŒ…è£…åœ¨ function_span() ä¸­
# 5. Guardrails è¢«åŒ…è£…åœ¨ guardrail_span() ä¸­
# 6. Handoffs è¢«åŒ…è£…åœ¨ handoff_span() ä¸­
# 7. éŸ³é¢‘è½¬å½•è¢«åŒ…è£…åœ¨ transcription_span() ä¸­
# 8. TTS è¢«åŒ…è£…åœ¨ speech_span() ä¸­
```

### 3.2 Trace ä¸ Span çš„å±‚æ¬¡ç»“æ„

```python
# openai-agents-python-main/src/agents/tracing/traces.py
class Trace(abc.ABC):
    """ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµ
    
    åŒ…å«ç›¸å…³çš„ Span å’Œå…ƒæ•°æ®
    """
    
    # å·¥ä½œæµåç§°
    workflow_name: str
    
    # å”¯ä¸€è¿½è¸ª IDï¼ˆæ ¼å¼ï¼štrace_<32_alphanumeric>ï¼‰
    trace_id: str
    
    # å¯é€‰åˆ†ç»„ IDï¼ˆå¦‚èŠå¤©çº¿ç¨‹ IDï¼‰
    group_id: str | None
    
    # å…ƒæ•°æ®
    metadata: dict[str, Any] | None

# Span è¡¨ç¤ºæœ‰å¼€å§‹å’Œç»“æŸæ—¶é—´çš„æ“ä½œ
# - started_at å’Œ ended_at æ—¶é—´æˆ³
# - trace_idï¼šæ‰€å±çš„ trace
# - parent_idï¼šçˆ¶ Spanï¼ˆå¦‚æœæœ‰ï¼‰
# - span_dataï¼šSpan çš„è¯¦ç»†ä¿¡æ¯
```

### 3.3 è‡ªå®šä¹‰è¿½è¸ª

```python
# åŸºæœ¬ç”¨æ³•
with trace("Order Processing") as t:
    validation_result = await Runner.run(validator, order_data)
    if validation_result.approved:
        await Runner.run(processor, order_data)

# å¸¦å…ƒæ•°æ®å’Œåˆ†ç»„
with trace(
    "Customer Service",
    group_id="chat_123",
    metadata={"customer": "user_456"}
) as t:
    result = await Runner.run(support_agent, query)
```

### 3.4 è¿½è¸ªé…ç½®

```python
# å…¨å±€ç¦ç”¨è¿½è¸ª
os.environ["OPENAI_AGENTS_DISABLE_TRACING"] = "1"

# å•æ¬¡è¿è¡Œç¦ç”¨è¿½è¸ª
RunConfig(tracing_disabled=True)
```

**è¿½è¸ªç‰¹æ€§ï¼š**
- **é›¶é…ç½®**ï¼šé»˜è®¤è‡ªåŠ¨è¿½è¸ªï¼Œæ— éœ€é¢å¤–è®¾ç½®
- **å±‚æ¬¡åŒ–**ï¼šTrace â†’ Span çš„æ¸…æ™°å±‚æ¬¡
- **äº‘é›†æˆ**ï¼šç›´æ¥æ¨é€åˆ° OpenAI Traces ä»ªè¡¨æ¿
- **çµæ´»æ§åˆ¶**ï¼šæ”¯æŒå…¨å±€æˆ–å•æ¬¡ç¦ç”¨

---

## å››ã€LangGraphï¼šæ—¶é—´æ—…è¡Œä¸æ£€æŸ¥ç‚¹å›é€€

### 4.1 æ—¶é—´æ—…è¡Œæ¦‚å¿µ

LangGraph çš„æ—¶é—´æ—…è¡ŒåŠŸèƒ½å…è®¸ä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œï¼Œæ”¯æŒä¸‰ç§ç”¨ä¾‹ï¼š

1. **ç†è§£æ¨ç†**ï¼šåˆ†ææˆåŠŸç»“æœçš„å†³ç­–æ­¥éª¤
2. **è°ƒè¯•é”™è¯¯**ï¼šå®šä½é”™è¯¯å‘ç”Ÿçš„ä½ç½®å’ŒåŸå› 
3. **æ¢ç´¢æ›¿ä»£æ–¹æ¡ˆ**ï¼šä¿®æ”¹çŠ¶æ€åé‡æ–°æ‰§è¡Œ

```python
# langgraph/docs/docs/concepts/time-travel.mdï¼ˆæ‘˜è¦ï¼‰
# æ—¶é—´æ—…è¡Œæµç¨‹ï¼š
# 1. è¿è¡Œå›¾å¹¶ä¿å­˜æ£€æŸ¥ç‚¹
# 2. ä½¿ç”¨ get_state_history() è·å–å†å²æ£€æŸ¥ç‚¹
# 3. ï¼ˆå¯é€‰ï¼‰ä½¿ç”¨ update_state() ä¿®æ”¹çŠ¶æ€
# 4. ä½¿ç”¨ checkpoint_id ä»ç‰¹å®šæ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œ
```

### 4.2 è·å–æ£€æŸ¥ç‚¹å†å²

```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, START, END

# é…ç½®æ£€æŸ¥ç‚¹
checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

# é¦–æ¬¡è¿è¡Œ
config = {"configurable": {"thread_id": "1"}}
result = graph.invoke({"question": "..."}, config)

# è·å–æ‰§è¡Œå†å²
history = list(graph.get_state_history(config))

for state in history:
    print(f"Step: {state.values}")
    print(f"Next: {state.next}")
    print(f"Checkpoint ID: {state.config['configurable']['checkpoint_id']}")
    print("---")
```

### 4.3 ä¿®æ”¹çŠ¶æ€å¹¶é‡æ–°æ‰§è¡Œ

```python
# 1. è·å–ç‰¹å®šæ£€æŸ¥ç‚¹çš„çŠ¶æ€
checkpoint_config = {
    "configurable": {
        "thread_id": "1",
        "checkpoint_id": "æŸä¸ªå†å²æ£€æŸ¥ç‚¹çš„ ID"
    }
}

current_state = graph.get_state(checkpoint_config)
print(f"Current state: {current_state.values}")

# 2. ä¿®æ”¹çŠ¶æ€
graph.update_state(
    checkpoint_config,
    {"documents": filtered_documents}  # ä¿®æ”¹åçš„çŠ¶æ€
)

# 3. ä»ä¿®æ”¹åçš„æ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œ
# ä¼ å…¥ None è¡¨ç¤ºä»å½“å‰çŠ¶æ€ç»§ç»­
result = graph.invoke(None, checkpoint_config)
```

### 4.4 å®¹é”™æ¢å¤

```python
# langgraph/libs/langgraph/tests/test_pregel.pyï¼ˆæ‘˜è¦ï¼‰
def test_checkpoint_recovery():
    """æµ‹è¯•æ£€æŸ¥ç‚¹å®¹é”™æ¢å¤"""
    
    class State(TypedDict):
        steps: Annotated[list[str], operator.add]
        attempt: int  # è¿½è¸ªå°è¯•æ¬¡æ•°
    
    def failing_node(state: State):
        # ç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œé‡è¯•æ—¶æˆåŠŸ
        if state["attempt"] == 1:
            raise RuntimeError("Simulated failure")
        return {"steps": ["node1"]}
    
    builder = StateGraph(State)
    builder.add_node("node1", failing_node)
    builder.add_node("node2", second_node)
    
    graph = builder.compile(checkpointer=sync_checkpointer)
    config = {"configurable": {"thread_id": "1"}}
    
    # ç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥
    with pytest.raises(RuntimeError):
        graph.invoke(
            {"steps": ["start"], "attempt": 1},
            config
        )
    
    # éªŒè¯æ£€æŸ¥ç‚¹çŠ¶æ€
    state = graph.get_state(config)
    assert state.values == {"steps": ["start"], "attempt": 1}
    assert state.next == ("node1",)  # åº”è¯¥é‡è¯•å¤±è´¥çš„èŠ‚ç‚¹
    assert "RuntimeError('Simulated failure')" in state.tasks[0].error
    
    # é‡è¯•å¹¶æ›´æ–°å°è¯•è®¡æ•°
    result = graph.invoke({"steps": [], "attempt": 2}, config)
    assert result == {"steps": ["start", "node1", "node2"], "attempt": 2}
    
    # éªŒè¯æ£€æŸ¥ç‚¹å†å²è®°å½•äº†ä¸¤æ¬¡å°è¯•
    history = list(graph.get_state_history(config))
    assert len(history) >= 2
    
    # éªŒè¯é”™è¯¯è¢«è®°å½•åœ¨æ£€æŸ¥ç‚¹ä¸­
    failed_checkpoint = next(c for c in history if c.tasks and c.tasks[0].error)
    assert "RuntimeError('Simulated failure')" in failed_checkpoint.tasks[0].error
```

**å®¹é”™ç‰¹æ€§ï¼š**
- **è‡ªåŠ¨ä¿å­˜å¤±è´¥çŠ¶æ€**ï¼šèŠ‚ç‚¹å¤±è´¥æ—¶ä¿å­˜æ£€æŸ¥ç‚¹
- **ä¿ç•™æˆåŠŸå†™å…¥**ï¼šå¹¶è¡ŒèŠ‚ç‚¹ä¸­æˆåŠŸçš„éƒ¨åˆ†ä¸ä¼šé‡æ–°æ‰§è¡Œ
- **é”™è¯¯ä¿¡æ¯ä¿ç•™**ï¼šæ£€æŸ¥ç‚¹åŒ…å«å®Œæ•´çš„é”™è¯¯å †æ ˆ
- **çµæ´»æ¢å¤**ï¼šå¯é€‰æ‹©ä»å¤±è´¥ç‚¹é‡è¯•æˆ–ä¿®æ”¹çŠ¶æ€åæ¢å¤

### 4.5 Pending Writes æœºåˆ¶

```markdown
# langgraph/docs/docs/concepts/persistence.mdï¼ˆæ‘˜è¦ï¼‰

å½“æŸä¸ªèŠ‚ç‚¹åœ¨è¶…çº§æ­¥éª¤ä¸­é—´å¤±è´¥æ—¶ï¼ŒLangGraph ä¼šä¿å­˜è¯¥è¶…çº§æ­¥éª¤ä¸­
å…¶ä»–æˆåŠŸå®Œæˆçš„èŠ‚ç‚¹çš„å¾…å†™å…¥ï¼ˆpending writesï¼‰ã€‚

è¿™æ ·ï¼Œå½“æˆ‘ä»¬ä»è¯¥è¶…çº§æ­¥éª¤æ¢å¤æ‰§è¡Œæ—¶ï¼Œå°±ä¸éœ€è¦é‡æ–°è¿è¡Œé‚£äº›
å·²ç»æˆåŠŸçš„èŠ‚ç‚¹ã€‚
```

---

## äº”ã€å·¥ç¨‹åŒ–æœ€ä½³å®è·µ

### 5.1 é”™è¯¯å¤„ç†ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | MathModelAgent | ADK | LangGraph | OpenAI SDK |
|------|----------------|-----|-----------|------------|
| **Agent çº§é‡è¯•** | âœ… æ™ºèƒ½åæ€ | âš ï¸ æ‰‹åŠ¨å®ç° | âœ… æ£€æŸ¥ç‚¹æ¢å¤ | âœ… è‡ªåŠ¨é‡è¯• |
| **LLM çº§é‡è¯•** | âœ… æŒ‡æ•°é€€é¿ | âœ… å†…ç½® | âœ… å†…ç½® | âœ… å†…ç½® |
| **å·¥å…·çº§é‡è¯•** | âœ… ä»£ç æ‰§è¡Œ | âœ… ç¡®è®¤é—¨ | âš ï¸ æ‰‹åŠ¨å®ç° | âš ï¸ æ‰‹åŠ¨å®ç° |
| **é”™è¯¯åæ€** | âœ… Prompt å¼•å¯¼ | âŒ | âŒ | âŒ |
| **çŠ¶æ€æ¢å¤** | âš ï¸ Redis æ¶ˆæ¯ | âš ï¸ Session | âœ… æ£€æŸ¥ç‚¹ | âš ï¸ æ‰‹åŠ¨å®ç° |

### 5.2 è¿½è¸ªä¸ç›‘æ§å¯¹æ¯”

| ç‰¹æ€§ | ADK | OpenAI SDK | LangGraph | MathModelAgent |
|------|-----|------------|-----------|----------------|
| **è‡ªåŠ¨è¿½è¸ª** | âœ… OTel | âœ… å†…ç½® | âš ï¸ éœ€é…ç½® | âŒ |
| **æ ‡å‡†åè®®** | âœ… OTel | âœ… OpenAI | âš ï¸ è‡ªå®šä¹‰ | âŒ |
| **äº‘é›†æˆ** | âœ… Vertex AI | âœ… OpenAI | âœ… LangSmith | âŒ |
| **è‡ªå®šä¹‰å¯¼å‡º** | âœ… Exporter | âœ… Processor | âœ… Callbacks | âš ï¸ æ‰‹åŠ¨ |
| **å¯è§†åŒ–** | âœ… GCP Console | âœ… Traces UI | âœ… Studio | âš ï¸ è‡ªå»º |

### 5.3 å®¹é”™æ¢å¤èƒ½åŠ›å¯¹æ¯”

| èƒ½åŠ› | LangGraph | ADK | OpenAI SDK | MathModelAgent |
|------|-----------|-----|------------|----------------|
| **æ£€æŸ¥ç‚¹** | âœ… è‡ªåŠ¨ | âœ… Session | âš ï¸ æ‰‹åŠ¨ | âš ï¸ Redis |
| **æ—¶é—´æ—…è¡Œ** | âœ… å†…ç½® | âŒ | âŒ | âŒ |
| **çŠ¶æ€ä¿®æ”¹** | âœ… update_state | âš ï¸ æ‰‹åŠ¨ | âš ï¸ æ‰‹åŠ¨ | âŒ |
| **å¹¶è¡Œå®¹é”™** | âœ… Pending Writes | âŒ | âŒ | âŒ |
| **é”™è¯¯è¯Šæ–­** | âœ… ä»»åŠ¡é”™è¯¯ | âœ… Span é”™è¯¯ | âœ… Span é”™è¯¯ | âš ï¸ æ—¥å¿— |

### 5.4 ç»„åˆç­–ç•¥å»ºè®®

**1. å°å‹é¡¹ç›®/å¿«é€ŸåŸå‹**
```python
# ä½¿ç”¨ OpenAI Agents SDK çš„é»˜è®¤è¿½è¸ª
from agents import Agent, Runner
from agents.tracing import trace

with trace("My Workflow"):
    result = Runner.run(agent, input)
```

**2. ä¼ä¸šçº§åº”ç”¨**
```python
# ADK + OpenTelemetry + è‡ªå®šä¹‰å¯¼å‡ºå™¨
from google.adk.agents import LlmAgent
from google.adk.telemetry import setup_otel

# é…ç½® OTel å¯¼å‡ºåˆ° Logfire/AgentOps
setup_otel(exporters=[LogfireExporter(), AgentOpsExporter()])

agent = LlmAgent(...)
result = await agent.run_async(ctx)
```

**3. éœ€è¦å®¹é”™ä¸å›é€€**
```python
# LangGraph + æ£€æŸ¥ç‚¹ + æ—¶é—´æ—…è¡Œ
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver(db_url)
graph = workflow.compile(checkpointer=checkpointer)

try:
    result = graph.invoke(input, config)
except Exception as e:
    # è·å–å¤±è´¥å‰çš„æ£€æŸ¥ç‚¹
    history = list(graph.get_state_history(config))
    last_good_checkpoint = history[1]  # å¤±è´¥å‰çš„çŠ¶æ€
    
    # ä¿®æ”¹çŠ¶æ€å¹¶é‡è¯•
    graph.update_state(last_good_checkpoint.config, modified_state)
    result = graph.invoke(None, last_good_checkpoint.config)
```

**4. éœ€è¦æ™ºèƒ½å®¹é”™**
```python
# MathModelAgent æ¨¡å¼ + è‡ªå®šä¹‰åæ€
async def smart_retry_agent(prompt: str, max_retries: int = 3):
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            result = await execute_with_tools(prompt)
            return result
        except ToolExecutionError as e:
            retry_count += 1
            
            # ç”Ÿæˆåæ€æç¤º
            reflection = f"""
            The previous attempt failed with error: {e}
            
            Please analyze the error and try a different approach.
            Consider: {get_error_hints(e)}
            """
            
            # å°†åæ€æ·»åŠ åˆ°å†å²
            prompt = reflection
```

---

## å…­ã€ç›‘æ§æŒ‡æ ‡ä¸å‘Šè­¦

### 6.1 å…³é”®æŒ‡æ ‡

**æ‰§è¡Œæ€§èƒ½ï¼š**
- å¹³å‡å“åº”æ—¶é—´
- P50/P95/P99 å»¶è¿Ÿ
- è¶…æ—¶ç‡

**èµ„æºæ¶ˆè€—ï¼š**
- Token ä½¿ç”¨é‡ï¼ˆè¾“å…¥/è¾“å‡ºï¼‰
- API è°ƒç”¨æ¬¡æ•°
- æˆæœ¬ç»Ÿè®¡

**å¯é æ€§ï¼š**
- æˆåŠŸç‡
- é‡è¯•ç‡
- é”™è¯¯ç±»å‹åˆ†å¸ƒ

**ä¸šåŠ¡æŒ‡æ ‡ï¼š**
- ä»»åŠ¡å®Œæˆç‡
- ç”¨æˆ·æ»¡æ„åº¦
- å·¥å…·è°ƒç”¨æˆåŠŸç‡

### 6.2 å‘Šè­¦ç­–ç•¥

```python
# ç¤ºä¾‹ï¼šåŸºäº OTel çš„å‘Šè­¦
from opentelemetry import metrics

meter = metrics.get_meter(__name__)

# åˆ›å»ºæŒ‡æ ‡
error_counter = meter.create_counter(
    "agent_errors_total",
    description="Total number of agent errors",
)

retry_counter = meter.create_counter(
    "agent_retries_total",
    description="Total number of agent retries",
)

latency_histogram = meter.create_histogram(
    "agent_latency_seconds",
    description="Agent execution latency",
)

# è®°å½•æŒ‡æ ‡
async def monitored_agent_run(agent, input):
    start_time = time.time()
    
    try:
        result = await agent.run(input)
        latency_histogram.record(time.time() - start_time)
        return result
    except Exception as e:
        error_counter.add(1, {"error_type": type(e).__name__})
        raise
```

### 6.3 æ—¥å¿—ç­–ç•¥

**åˆ†çº§æ—¥å¿—ï¼š**
```python
# DEBUG: è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
logger.debug(f"LLM request: {request}")

# INFO: å…³é”®æ‰§è¡Œæ­¥éª¤
logger.info(f"Agent started: {agent.name}")

# WARNING: é‡è¯•å’Œé™çº§
logger.warning(f"Retry {attempt}/{max_retries}: {error}")

# ERROR: æ‰§è¡Œå¤±è´¥
logger.error(f"Agent failed: {error}", exc_info=True)
```

**ç»“æ„åŒ–æ—¥å¿—ï¼š**
```python
logger.info(
    "Agent execution completed",
    extra={
        "agent_name": agent.name,
        "task_id": task_id,
        "duration_ms": duration,
        "token_count": token_count,
        "retry_count": retry_count,
    }
)
```

---

## ä¸ƒã€æ€»ç»“

å·¥ç¨‹åŒ–ä¸å®¹é”™ç›‘æ§å±‚æ˜¯ç”Ÿäº§çº§ Agent ç³»ç»Ÿçš„**è´¨é‡ä¿éšœ**ï¼š

**æ ¸å¿ƒèƒ½åŠ›çŸ©é˜µï¼š**

| èƒ½åŠ› | å®ç°æ–¹æ¡ˆ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **æ™ºèƒ½å®¹é”™** | MathModelAgent åæ€æœºåˆ¶ | ğŸ”´ é«˜ |
| **è‡ªåŠ¨è¿½è¸ª** | ADK OTel / OpenAI SDK | ğŸ”´ é«˜ |
| **æ£€æŸ¥ç‚¹æ¢å¤** | LangGraph æ—¶é—´æ—…è¡Œ | ğŸŸ¡ ä¸­ |
| **æ€§èƒ½ç›‘æ§** | OTel + Prometheus | ğŸ”´ é«˜ |
| **æˆæœ¬è¿½è¸ª** | Token ç»Ÿè®¡ + å‘Šè­¦ | ğŸŸ¡ ä¸­ |
| **æ—¥å¿—åˆ†æ** | ç»“æ„åŒ–æ—¥å¿— + ELK | ğŸ”´ é«˜ |

**å®æ–½è·¯çº¿å›¾ï¼š**

1. **ç¬¬ä¸€é˜¶æ®µï¼ˆMVPï¼‰**ï¼š
   - åŸºç¡€æ—¥å¿—è®°å½•
   - ç®€å•é‡è¯•æœºåˆ¶
   - é”™è¯¯æ•è·ä¸ä¸ŠæŠ¥

2. **ç¬¬äºŒé˜¶æ®µï¼ˆç”Ÿäº§ï¼‰**ï¼š
   - OpenTelemetry è¿½è¸ª
   - æ£€æŸ¥ç‚¹æŒä¹…åŒ–
   - æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

3. **ç¬¬ä¸‰é˜¶æ®µï¼ˆä¼˜åŒ–ï¼‰**ï¼š
   - æ™ºèƒ½é”™è¯¯åæ€
   - æ—¶é—´æ—…è¡Œè°ƒè¯•
   - è‡ªåŠ¨åŒ–å‘Šè­¦ä¸ä¿®å¤

é€šè¿‡ç³»ç»ŸåŒ–çš„å·¥ç¨‹å®è·µï¼Œå¯ä»¥æ„å»º**å¯è§‚æµ‹ã€å¯æ¢å¤ã€å¯ä¼˜åŒ–**çš„ç”Ÿäº§çº§ Agent ç³»ç»Ÿï¼Œç¡®ä¿åœ¨å¤æ‚åœºæ™¯ä¸‹çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚

