# Vercel AI SDK - é—®ç­”æ–‡æ¡£ (QA)

## ğŸ“‹ ç›®å½•
- [StreamTextæ ¸å¿ƒæ¶æ„](#streamtextæ ¸å¿ƒæ¶æ„)
- [å·¥å…·é…ç½®ç³»ç»Ÿ](#å·¥å…·é…ç½®ç³»ç»Ÿ)
- [è½¬æ¢æµæœºåˆ¶](#è½¬æ¢æµæœºåˆ¶)
- [æµå¼å¤„ç†è¯¦è§£](#æµå¼å¤„ç†è¯¦è§£)
- [React Hooksé›†æˆ](#react-hooksé›†æˆ)
- [å¤šæ¨¡æ€æ”¯æŒ](#å¤šæ¨¡æ€æ”¯æŒ)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [éƒ¨ç½²å’Œé›†æˆ](#éƒ¨ç½²å’Œé›†æˆ)

---

## StreamTextæ ¸å¿ƒæ¶æ„

### Q1: StreamTextçš„å·¥å…·é…ç½®ï¼ˆtoolChoice, activeToolsï¼‰æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

**A:** å·¥å…·é…ç½®æ˜¯æ§åˆ¶AIæ™ºèƒ½ä½“å¦‚ä½•é€‰æ‹©å’Œä½¿ç”¨å·¥å…·çš„æ ¸å¿ƒæœºåˆ¶ã€‚

#### å·¥å…·é…ç½®è¯¦è§£

**1. toolChoice - å·¥å…·é€‰æ‹©ç­–ç•¥**
```typescript
// 1. è‡ªåŠ¨é€‰æ‹©ï¼ˆé»˜è®¤ï¼‰
const result = streamText({
  model: openai('gpt-4'),
  tools: {
    getWeather: tool({
      description: 'è·å–å¤©æ°”ä¿¡æ¯',
      parameters: z.object({ city: z.string() }),
      execute: async ({ city }) => getWeatherData(city)
    }),
    searchWeb: tool({
      description: 'æœç´¢ç½‘é¡µ',
      parameters: z.object({ query: z.string() }),
      execute: async ({ query }) => searchInternet(query)
    })
  },
  toolChoice: 'auto', // AIè‡ªåŠ¨å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ä»¥åŠä½¿ç”¨å“ªä¸ªå·¥å…·
  prompt: 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
});

// 2. å¼ºåˆ¶ä½¿ç”¨å·¥å…·
const result = streamText({
  model: openai('gpt-4'),
  tools: { getWeather },
  toolChoice: 'required', // å¿…é¡»ä½¿ç”¨å·¥å…·ï¼Œä¸èƒ½ç›´æ¥å›ç­”
  prompt: 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
});

// 3. ç¦ç”¨å·¥å…·
const result = streamText({
  model: openai('gpt-4'),
  tools: { getWeather },
  toolChoice: 'none', // ç¦ç”¨æ‰€æœ‰å·¥å…·ï¼Œåªèƒ½åŸºäºçŸ¥è¯†å›ç­”
  prompt: 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
});

// 4. æŒ‡å®šç‰¹å®šå·¥å…·
const result = streamText({
  model: openai('gpt-4'),
  tools: { getWeather, searchWeb },
  toolChoice: {
    type: 'tool',
    toolName: 'getWeather' // å¼ºåˆ¶ä½¿ç”¨getWeatherå·¥å…·
  },
  prompt: 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
});
```

**2. activeTools - åŠ¨æ€å·¥å…·æ¿€æ´»**
```typescript
// åŸºäºä¸Šä¸‹æ–‡åŠ¨æ€æ¿€æ´»å·¥å…·
const activeToolsExample = streamText({
  model: openai('gpt-4'),
  tools: {
    // æ•°æ®åº“å·¥å…·
    queryDatabase: tool({
      description: 'æŸ¥è¯¢æ•°æ®åº“',
      parameters: z.object({ sql: z.string() }),
      execute: async ({ sql }) => executeQuery(sql)
    }),
    
    // é‚®ä»¶å·¥å…·  
    sendEmail: tool({
      description: 'å‘é€é‚®ä»¶',
      parameters: z.object({
        to: z.string(),
        subject: z.string(),
        body: z.string()
      }),
      execute: async ({ to, subject, body }) => sendMail(to, subject, body)
    }),
    
    // æ–‡ä»¶æ“ä½œå·¥å…·
    readFile: tool({
      description: 'è¯»å–æ–‡ä»¶',
      parameters: z.object({ path: z.string() }),
      execute: async ({ path }) => readFileContent(path)
    })
  },
  
  // åŠ¨æ€æ§åˆ¶å“ªäº›å·¥å…·å¯ç”¨
  activeTools: async (context) => {
    const userRole = await getUserRole(context.userId);
    
    // æ ¹æ®ç”¨æˆ·æƒé™åŠ¨æ€æ¿€æ´»å·¥å…·
    if (userRole === 'admin') {
      return ['queryDatabase', 'sendEmail', 'readFile']; // ç®¡ç†å‘˜å…¨éƒ¨æƒé™
    } else if (userRole === 'user') {
      return ['readFile']; // æ™®é€šç”¨æˆ·åªèƒ½è¯»æ–‡ä»¶
    } else {
      return []; // è®¿å®¢æ— å·¥å…·æƒé™
    }
  },
  
  prompt: 'å¸®æˆ‘æŸ¥è¯¢ç”¨æˆ·æ•°æ®å¹¶å‘é€æŠ¥å‘Šé‚®ä»¶'
});
```

#### å®é™…åº”ç”¨åœºæ™¯

**åœºæ™¯1: æ™ºèƒ½å®¢æœç³»ç»Ÿ**
```typescript
const customerServiceAgent = streamText({
  model: openai('gpt-4'),
  tools: {
    lookupCustomer: tool({
      description: 'æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯',
      parameters: z.object({ customerId: z.string() }),
      execute: async ({ customerId }) => getCustomerInfo(customerId)
    }),
    
    checkOrderStatus: tool({
      description: 'æ£€æŸ¥è®¢å•çŠ¶æ€',
      parameters: z.object({ orderId: z.string() }),
      execute: async ({ orderId }) => getOrderStatus(orderId)
    }),
    
    processRefund: tool({
      description: 'å¤„ç†é€€æ¬¾',
      parameters: z.object({ orderId: z.string(), reason: z.string() }),
      execute: async ({ orderId, reason }) => initiateRefund(orderId, reason)
    })
  },
  
  // æ ¹æ®å¯¹è¯é˜¶æ®µåŠ¨æ€è°ƒæ•´å·¥å…·ç­–ç•¥
  toolChoice: async (context) => {
    const conversationStage = analyzeConversationStage(context.messages);
    
    switch (conversationStage) {
      case 'greeting':
        return 'none'; // é—®å€™é˜¶æ®µä¸éœ€è¦å·¥å…·
      case 'information_gathering':
        return 'auto'; // ä¿¡æ¯æ”¶é›†é˜¶æ®µè‡ªåŠ¨é€‰æ‹©å·¥å…·
      case 'problem_solving':
        return 'required'; // é—®é¢˜è§£å†³é˜¶æ®µå¿…é¡»ä½¿ç”¨å·¥å…·
      default:
        return 'auto';
    }
  },
  
  activeTools: async (context) => {
    const customerTier = await getCustomerTier(context.customerId);
    
    // VIPå®¢æˆ·å¯ä»¥ç›´æ¥å¤„ç†é€€æ¬¾
    if (customerTier === 'VIP') {
      return ['lookupCustomer', 'checkOrderStatus', 'processRefund'];
    } else {
      return ['lookupCustomer', 'checkOrderStatus']; // æ™®é€šå®¢æˆ·éœ€è¦äººå·¥å®¡æ ¸é€€æ¬¾
    }
  }
});
```

---

### Q2: è½¬æ¢æµï¼ˆexperimental_transformï¼‰æ˜¯ä»€ä¹ˆæ¦‚å¿µï¼Ÿ

**A:** è½¬æ¢æµæ˜¯å¯¹AIç”Ÿæˆå†…å®¹è¿›è¡Œå®æ—¶å¤„ç†å’Œè½¬æ¢çš„ç®¡é“æœºåˆ¶ï¼Œç±»ä¼¼äºUnixçš„ç®¡é“æ“ä½œã€‚

#### è½¬æ¢æµçš„æ ¸å¿ƒæ¦‚å¿µ

**1. åŸºç¡€è½¬æ¢æµ**
```typescript
// ç®€å•çš„æ–‡æœ¬è½¬æ¢
const uppercaseTransform = new TransformStream({
  transform(chunk, controller) {
    if (chunk.type === 'text-delta') {
      // å°†æ‰€æœ‰æ–‡æœ¬è½¬ä¸ºå¤§å†™
      controller.enqueue({
        ...chunk,
        text: chunk.text.toUpperCase()
      });
    } else {
      controller.enqueue(chunk);
    }
  }
});

const result = streamText({
  model: openai('gpt-4'),
  prompt: 'Tell me about TypeScript',
  experimental_transform: [uppercaseTransform]
});

// åŸå§‹è¾“å‡º: "TypeScript is a programming language..."
// è½¬æ¢å: "TYPESCRIPT IS A PROGRAMMING LANGUAGE..."
```

**2. å¤šå±‚è½¬æ¢ç®¡é“**
```typescript
// åˆ›å»ºå¤šä¸ªè½¬æ¢å™¨
const profanityFilter = new TransformStream({
  transform(chunk, controller) {
    if (chunk.type === 'text-delta') {
      // è¿‡æ»¤æ•æ„Ÿè¯
      const filteredText = chunk.text.replace(/badword/gi, '***');
      controller.enqueue({
        ...chunk,
        text: filteredText
      });
    } else {
      controller.enqueue(chunk);
    }
  }
});

const markdownFormatter = new TransformStream({
  transform(chunk, controller) {
    if (chunk.type === 'text-delta') {
      // è‡ªåŠ¨æ·»åŠ markdownæ ¼å¼
      const formattedText = autoMarkdown(chunk.text);
      controller.enqueue({
        ...chunk,
        text: formattedText
      });
    } else {
      controller.enqueue(chunk);
    }
  }
});

const translationTransform = new TransformStream({
  transform(chunk, controller) {
    if (chunk.type === 'text-delta') {
      // å®æ—¶ç¿»è¯‘
      translateText(chunk.text, 'zh-CN').then(translated => {
        controller.enqueue({
          ...chunk,
          text: translated,
          metadata: { original: chunk.text, language: 'zh-CN' }
        });
      });
    } else {
      controller.enqueue(chunk);
    }
  }
});

// ç»„åˆå¤šä¸ªè½¬æ¢å™¨
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'Explain machine learning',
  experimental_transform: [
    profanityFilter,    // 1. å…ˆè¿‡æ»¤æ•æ„Ÿè¯
    markdownFormatter,  // 2. ç„¶åæ ¼å¼åŒ–
    translationTransform // 3. æœ€åç¿»è¯‘
  ]
});
```

#### é«˜çº§è½¬æ¢æµåº”ç”¨

**1. å®æ—¶æ•°æ®å¢å¼º**
```typescript
class DataEnhancementTransform extends TransformStream {
  constructor(private knowledgeBase: KnowledgeBase) {
    super({
      transform: async (chunk, controller) => {
        if (chunk.type === 'text-delta') {
          // å®æ—¶å¢å¼ºå†…å®¹
          const enhancedText = await this.enhanceContent(chunk.text);
          controller.enqueue({
            ...chunk,
            text: enhancedText.text,
            metadata: {
              ...chunk.metadata,
              enhancements: enhancedText.enhancements,
              confidence: enhancedText.confidence
            }
          });
        } else {
          controller.enqueue(chunk);
        }
      }
    });
  }

  private async enhanceContent(text: string) {
    // 1. å®ä½“è¯†åˆ«å’Œé“¾æ¥
    const entities = await this.knowledgeBase.extractEntities(text);
    
    // 2. äº‹å®éªŒè¯
    const factCheck = await this.knowledgeBase.verifyFacts(text);
    
    // 3. ç›¸å…³ä¿¡æ¯è¡¥å……
    const relatedInfo = await this.knowledgeBase.getRelatedInfo(entities);
    
    return {
      text: this.injectEnhancements(text, entities, relatedInfo),
      enhancements: {
        entities,
        factCheck,
        relatedInfo
      },
      confidence: factCheck.confidence
    };
  }
}

// ä½¿ç”¨æ•°æ®å¢å¼ºè½¬æ¢æµ
const enhancedAgent = streamText({
  model: openai('gpt-4'),
  prompt: 'ä»‹ç»ä¸€ä¸‹åŸƒéš†Â·é©¬æ–¯å…‹',
  experimental_transform: [
    new DataEnhancementTransform(knowledgeBase)
  ]
});

// è¾“å‡ºç¤ºä¾‹:
// åŸå§‹: "åŸƒéš†Â·é©¬æ–¯å…‹æ˜¯ä¸€ä½ä¼ä¸šå®¶"
// å¢å¼ºå: "åŸƒéš†Â·é©¬æ–¯å…‹[é“¾æ¥:ç»´åŸºç™¾ç§‘]æ˜¯ä¸€ä½ä¼ä¸šå®¶ï¼Œç›®å‰æ‹…ä»»ç‰¹æ–¯æ‹‰CEO[éªŒè¯:âœ“]ï¼Œå‡€èµ„äº§çº¦$240B[æ›´æ–°:2025-01-27]"
```

**2. å¤šè¯­è¨€å®æ—¶ç¿»è¯‘æµ**
```typescript
class MultiLanguageTransform extends TransformStream {
  constructor(private targetLanguages: string[]) {
    super({
      transform: async (chunk, controller) => {
        if (chunk.type === 'text-delta') {
          // ä¸ºæ¯ç§ç›®æ ‡è¯­è¨€åˆ›å»ºç¿»è¯‘
          const translations = await Promise.all(
            this.targetLanguages.map(async (lang) => ({
              language: lang,
              text: await translateText(chunk.text, lang)
            }))
          );

          controller.enqueue({
            type: 'multilingual-delta',
            original: chunk.text,
            translations,
            timestamp: Date.now()
          });
        } else {
          controller.enqueue(chunk);
        }
      }
    });
  }
}

// å¤šè¯­è¨€å®¢æœç³»ç»Ÿ
const multilingualSupport = streamText({
  model: openai('gpt-4'),
  prompt: 'How can I help you today?',
  experimental_transform: [
    new MultiLanguageTransform(['zh-CN', 'es', 'fr', 'ja'])
  ]
});

// å®æ—¶è¾“å‡ºå¤šè¯­è¨€ç‰ˆæœ¬:
// English: "I can help you with your order"
// ä¸­æ–‡: "æˆ‘å¯ä»¥å¸®åŠ©æ‚¨å¤„ç†è®¢å•"  
// EspaÃ±ol: "Puedo ayudarte con tu pedido"
// FranÃ§ais: "Je peux vous aider avec votre commande"
// æ—¥æœ¬èª: "ã”æ³¨æ–‡ã«ã¤ã„ã¦ãŠæ‰‹ä¼ã„ã§ãã¾ã™"
```

**3. æƒ…æ„Ÿåˆ†æå’Œå“åº”è°ƒæ•´**
```typescript
class EmotionalToneTransform extends TransformStream {
  constructor(private emotionAnalyzer: EmotionAnalyzer) {
    super({
      transform: async (chunk, controller) => {
        if (chunk.type === 'text-delta') {
          // åˆ†ææƒ…æ„Ÿ
          const emotion = await this.emotionAnalyzer.analyze(chunk.text);
          
          // æ ¹æ®æ£€æµ‹åˆ°çš„æƒ…æ„Ÿè°ƒæ•´è¯­è°ƒ
          const adjustedText = this.adjustTone(chunk.text, emotion);
          
          controller.enqueue({
            ...chunk,
            text: adjustedText,
            metadata: {
              ...chunk.metadata,
              emotion: emotion,
              toneAdjustment: true
            }
          });
        } else {
          controller.enqueue(chunk);
        }
      }
    });
  }

  private adjustTone(text: string, emotion: EmotionData): string {
    switch (emotion.dominant) {
      case 'anger':
        return this.makeToneCalming(text);
      case 'sadness':
        return this.makeToneComforting(text);
      case 'anxiety':
        return this.makeToneReassuring(text);
      default:
        return text;
    }
  }
}

// æƒ…æ„Ÿæ™ºèƒ½å®¢æœ
const emotionallyAwareAgent = streamText({
  model: openai('gpt-4'),
  prompt: userMessage,
  experimental_transform: [
    new EmotionalToneTransform(emotionAnalyzer)
  ]
});
```

---

### Q3: æµå¼é…ç½®ï¼ˆonChunk, onFinish, onError, onStepFinishï¼‰çš„å…·ä½“ä½œç”¨ï¼Ÿ

**A:** æµå¼é…ç½®æ˜¯å¤„ç†AIç”Ÿæˆè¿‡ç¨‹ä¸­å„ä¸ªé˜¶æ®µäº‹ä»¶çš„å›è°ƒå‡½æ•°ç³»ç»Ÿã€‚

#### æµå¼äº‹ä»¶å¤„ç†è¯¦è§£

**1. onChunk - å®æ—¶æ•°æ®å—å¤„ç†**
```typescript
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'å†™ä¸€ä¸ªæ•…äº‹',
  onChunk: ({ chunk, snapshot }) => {
    console.log('å®æ—¶æ•°æ®å—ç±»å‹:', chunk.type);
    
    switch (chunk.type) {
      case 'text-delta':
        // æ–‡æœ¬å¢é‡æ›´æ–°
        console.log('æ–°æ–‡æœ¬ç‰‡æ®µ:', chunk.text);
        updateUI(chunk.text); // å®æ—¶æ›´æ–°ç”¨æˆ·ç•Œé¢
        break;
        
      case 'tool-call-start':
        // å·¥å…·è°ƒç”¨å¼€å§‹
        console.log('å¼€å§‹è°ƒç”¨å·¥å…·:', chunk.toolName);
        showToolLoadingIndicator(chunk.toolName);
        break;
        
      case 'tool-call-result':
        // å·¥å…·è°ƒç”¨ç»“æœ
        console.log('å·¥å…·è°ƒç”¨ç»“æœ:', chunk.result);
        hideToolLoadingIndicator();
        displayToolResult(chunk.result);
        break;
        
      case 'error':
        // é”™è¯¯å¤„ç†
        console.error('æµå¼å¤„ç†é”™è¯¯:', chunk.error);
        displayError(chunk.error);
        break;
    }
    
    // å½“å‰å®Œæ•´å¿«ç…§
    console.log('å½“å‰å®Œæ•´å†…å®¹:', snapshot.text);
    console.log('å½“å‰ä½¿ç”¨çš„å·¥å…·:', snapshot.toolCalls);
  }
});
```

**2. onFinish - å®Œæˆæ—¶çš„ç»¼åˆå¤„ç†**
```typescript
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'åˆ†æè¿™ä¸ªæ•°æ®é›†',
  tools: { analyzeData, generateChart },
  onFinish: async ({ text, toolCalls, usage, finishReason }) => {
    console.log('=== æ‰§è¡Œå®Œæˆ ===');
    console.log('æœ€ç»ˆæ–‡æœ¬:', text);
    console.log('è°ƒç”¨çš„å·¥å…·:', toolCalls);
    console.log('tokenä½¿ç”¨æƒ…å†µ:', usage);
    console.log('ç»“æŸåŸå› :', finishReason);
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    await saveConversation({
      userId: currentUser.id,
      content: text,
      toolCalls: toolCalls,
      metrics: {
        inputTokens: usage.inputTokens,
        outputTokens: usage.outputTokens,
        totalCost: calculateCost(usage),
        duration: Date.now() - startTime
      }
    });
    
    // å‘é€å®Œæˆé€šçŸ¥
    await sendNotification({
      type: 'task_completed',
      message: 'æ•°æ®åˆ†æå·²å®Œæˆ',
      results: text
    });
    
    // æ¸…ç†èµ„æº
    cleanupTempFiles();
  }
});
```

**3. onError - é”™è¯¯å¤„ç†å’Œæ¢å¤**
```typescript
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'å¤æ‚çš„æ•°æ®å¤„ç†ä»»åŠ¡',
  tools: { processData, queryDatabase },
  onError: async ({ error, prompt, messages }) => {
    console.error('æ‰§è¡Œå‡ºé”™:', error);
    
    // é”™è¯¯åˆ†ç±»å’Œå¤„ç†
    if (error.name === 'RateLimitError') {
      // é€Ÿç‡é™åˆ¶é”™è¯¯ - è‡ªåŠ¨é‡è¯•
      console.log('é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•...');
      await delay(exponentialBackoff(retryCount));
      return await retryRequest({ prompt, messages });
      
    } else if (error.name === 'ToolExecutionError') {
      // å·¥å…·æ‰§è¡Œé”™è¯¯ - é™çº§å¤„ç†
      console.log('å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ');
      return await fallbackExecution({ prompt, messages });
      
    } else if (error.name === 'ContextLengthExceededError') {
      // ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™ - å‹ç¼©å†å²
      console.log('ä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œå‹ç¼©å¯¹è¯å†å²');
      const compressedMessages = await compressConversationHistory(messages);
      return await streamText({ prompt, messages: compressedMessages });
      
    } else {
      // å…¶ä»–é”™è¯¯ - è®°å½•å¹¶é€šçŸ¥
      await logError({
        error: error,
        context: { prompt, messages },
        userId: currentUser.id,
        timestamp: new Date()
      });
      
      await notifyAdmin({
        type: 'critical_error',
        error: error.message,
        user: currentUser.id
      });
      
      throw error; // é‡æ–°æŠ›å‡ºæ— æ³•å¤„ç†çš„é”™è¯¯
    }
  }
});
```

**4. onStepFinish - å¤šæ­¥éª¤ä»»åŠ¡çš„æ­¥éª¤å®Œæˆå¤„ç†**
```typescript
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'æ‰§è¡Œå®Œæ•´çš„æ•°æ®åˆ†ææµç¨‹',
  tools: {
    loadData: tool({ /* ... */ }),
    cleanData: tool({ /* ... */ }),
    analyzeData: tool({ /* ... */ }),
    generateReport: tool({ /* ... */ })
  },
  onStepFinish: async ({ text, toolCalls, stepNumber, isLastStep }) => {
    console.log(`=== æ­¥éª¤ ${stepNumber} å®Œæˆ ===`);
    console.log('æœ¬æ­¥éª¤è¾“å‡º:', text);
    console.log('æœ¬æ­¥éª¤å·¥å…·è°ƒç”¨:', toolCalls);
    
    // æ›´æ–°è¿›åº¦æ¡
    updateProgressBar({
      current: stepNumber,
      total: estimatedTotalSteps,
      status: isLastStep ? 'completed' : 'in-progress'
    });
    
    // ä¿å­˜ä¸­é—´ç»“æœ
    await saveIntermediateResult({
      stepNumber,
      content: text,
      toolCalls,
      timestamp: new Date()
    });
    
    // å‘é€æ­¥éª¤å®Œæˆé€šçŸ¥
    await sendStepNotification({
      stepNumber,
      description: getStepDescription(stepNumber),
      completed: true,
      isLastStep
    });
    
    // å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œæ‰§è¡Œæœ€ç»ˆå¤„ç†
    if (isLastStep) {
      await performFinalProcessing();
    }
  }
});
```

#### ç»¼åˆåº”ç”¨ç¤ºä¾‹ï¼šæ™ºèƒ½æ–‡æ¡£ç”Ÿæˆç³»ç»Ÿ

```typescript
class DocumentGenerationSystem {
  async generateDocument(requirements: DocumentRequirements) {
    const startTime = Date.now();
    let currentProgress = 0;
    const totalSteps = 5; // é¢„ä¼°æ­¥éª¤æ•°
    
    return streamText({
      model: openai('gpt-4'),
      prompt: `æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆæ–‡æ¡£: ${requirements.description}`,
      tools: {
        researchTopic: this.createResearchTool(),
        generateOutline: this.createOutlineTool(),
        writeSection: this.createSectionTool(),
        addImages: this.createImageTool(),
        formatDocument: this.createFormatterTool()
      },
      
      // å®æ—¶å¤„ç†æ¯ä¸ªæ•°æ®å—
      onChunk: ({ chunk, snapshot }) => {
        switch (chunk.type) {
          case 'text-delta':
            // å®æ—¶æ˜¾ç¤ºç”Ÿæˆçš„æ–‡æœ¬
            this.ui.appendText(chunk.text);
            break;
            
          case 'tool-call-start':
            // æ˜¾ç¤ºå·¥å…·è°ƒç”¨çŠ¶æ€
            this.ui.showToolStatus(chunk.toolName, 'running');
            this.analytics.recordToolUsage(chunk.toolName);
            break;
            
          case 'tool-call-result':
            // æ˜¾ç¤ºå·¥å…·ç»“æœ
            this.ui.showToolStatus(chunk.toolCallId, 'completed');
            this.ui.displayToolResult(chunk.result);
            break;
        }
      },
      
      // æ­¥éª¤å®Œæˆå¤„ç†
      onStepFinish: async ({ stepNumber, text, toolCalls, isLastStep }) => {
        currentProgress = (stepNumber / totalSteps) * 100;
        
        // æ›´æ–°è¿›åº¦
        this.ui.updateProgress({
          percentage: currentProgress,
          currentStep: this.getStepName(stepNumber),
          isComplete: isLastStep
        });
        
        // ä¿å­˜ç‰ˆæœ¬å†å²
        await this.versionControl.saveVersion({
          step: stepNumber,
          content: text,
          toolResults: toolCalls.map(tc => tc.result),
          timestamp: new Date()
        });
        
        // è´¨é‡æ£€æŸ¥
        const qualityScore = await this.qualityChecker.evaluate(text);
        if (qualityScore < 0.7) {
          await this.sendQualityAlert(stepNumber, qualityScore);
        }
      },
      
      // å®Œæˆå¤„ç†
      onFinish: async ({ text, toolCalls, usage, finishReason }) => {
        const executionTime = Date.now() - startTime;
        
        // ä¿å­˜æœ€ç»ˆæ–‡æ¡£
        const document = await this.documentManager.save({
          content: text,
          requirements: requirements,
          metadata: {
            generatedAt: new Date(),
            executionTime,
            tokenUsage: usage,
            toolsUsed: toolCalls.map(tc => tc.toolName),
            qualityScore: await this.qualityChecker.evaluateFinal(text)
          }
        });
        
        // å‘é€å®Œæˆé€šçŸ¥
        await this.notificationService.sendCompletion({
          documentId: document.id,
          recipient: requirements.userId,
          stats: {
            wordCount: this.countWords(text),
            executionTime,
            cost: this.calculateCost(usage)
          }
        });
        
        // åˆ†æå’Œå­¦ä¹ 
        await this.analytics.recordCompletion({
          requirements,
          result: text,
          performance: { executionTime, tokenUsage: usage },
          userSatisfaction: await this.getUserFeedback(document.id)
        });
      },
      
      // é”™è¯¯å¤„ç†
      onError: async ({ error, prompt, messages }) => {
        // è®°å½•é”™è¯¯
        await this.errorLogger.log({
          error,
          context: { prompt, requirements },
          timestamp: new Date(),
          userId: requirements.userId
        });
        
        // å°è¯•æ¢å¤
        if (error.name === 'ToolExecutionError') {
          return await this.tryFallbackGeneration(requirements);
        }
        
        // é€šçŸ¥ç”¨æˆ·
        await this.notificationService.sendError({
          userId: requirements.userId,
          error: error.message,
          supportTicketId: await this.createSupportTicket(error, requirements)
        });
        
        throw error;
      }
    });
  }
}
```

---

### Q4: stopWhenåœæ­¢æ¡ä»¶æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

**A:** stopWhenæ˜¯æ§åˆ¶AIæ‰§è¡Œåœæ­¢æ—¶æœºçš„æ™ºèƒ½æ¡ä»¶ç³»ç»Ÿã€‚

#### åœæ­¢æ¡ä»¶ç±»å‹

**1. æ­¥éª¤è®¡æ•°åœæ­¢**
```typescript
import { stepCountIs, stepCountIsGreaterThan } from 'ai';

// æ‰§è¡Œå›ºå®šæ­¥éª¤ååœæ­¢
const result = streamText({
  model: openai('gpt-4'),
  prompt: 'åˆ†æè¿™ä¸ªé—®é¢˜',
  tools: { analyze, research, summarize },
  stopWhen: stepCountIs(3) // æ‰§è¡Œ3ä¸ªæ­¥éª¤ååœæ­¢
});

// æ‰§è¡Œè¶…è¿‡æŒ‡å®šæ­¥éª¤æ•°åœæ­¢
const result2 = streamText({
  model: openai('gpt-4'),
  prompt: 'æ·±åº¦ç ”ç©¶è¿™ä¸ªè¯é¢˜',
  tools: { research, analyze, crossReference },
  stopWhen: stepCountIsGreaterThan(5) // è¶…è¿‡5æ­¥åœæ­¢ï¼Œé˜²æ­¢æ— é™å¾ªç¯
});
```

**2. è‡ªå®šä¹‰æ¡ä»¶åœæ­¢**
```typescript
// åŸºäºå†…å®¹çš„åœæ­¢æ¡ä»¶
const contentBasedStop = (result) => {
  // å½“ç”Ÿæˆçš„å†…å®¹åŒ…å«ç»“è®ºæ ‡å¿—æ—¶åœæ­¢
  return result.text.includes('## ç»“è®º') || 
         result.text.includes('ç»¼ä¸Šæ‰€è¿°') ||
         result.text.length > 5000; // æˆ–è€…å†…å®¹é•¿åº¦è¶…é™
};

// åŸºäºå·¥å…·è°ƒç”¨çš„åœæ­¢æ¡ä»¶
const toolBasedStop = (result) => {
  // å½“è°ƒç”¨äº†ç‰¹å®šå·¥å…·ç»„åˆæ—¶åœæ­¢
  const calledTools = result.toolCalls.map(tc => tc.toolName);
  return calledTools.includes('generateFinalReport') ||
         calledTools.length > 10; // æˆ–è€…å·¥å…·è°ƒç”¨æ¬¡æ•°è¿‡å¤š
};

// åŸºäºè´¨é‡è¯„ä¼°çš„åœæ­¢æ¡ä»¶
const qualityBasedStop = async (result) => {
  const qualityScore = await evaluateQuality(result.text);
  return qualityScore > 0.85; // è´¨é‡è¾¾æ ‡æ—¶åœæ­¢
};

// ç»„åˆåœæ­¢æ¡ä»¶
const combinedStop = (result) => {
  return contentBasedStop(result) || 
         toolBasedStop(result) ||
         result.usage.totalTokens > 50000; // æˆ–è€…tokenä½¿ç”¨è¶…é™
};

const result = streamText({
  model: openai('gpt-4'),
  prompt: 'åˆ›å»ºå®Œæ•´çš„åˆ†ææŠ¥å‘Š',
  tools: { research, analyze, writeSection, generateChart, finalizeReport },
  stopWhen: combinedStop
});
```

**3. æ—¶é—´å’Œèµ„æºé™åˆ¶åœæ­¢**
```typescript
// æ—¶é—´é™åˆ¶åœæ­¢æ¡ä»¶
const timeBasedStop = (() => {
  const startTime = Date.now();
  const maxDuration = 5 * 60 * 1000; // 5åˆ†é’Ÿ
  
  return (result) => {
    const elapsed = Date.now() - startTime;
    return elapsed > maxDuration;
  };
})();

// æˆæœ¬é™åˆ¶åœæ­¢æ¡ä»¶
const costBasedStop = (() => {
  const maxCost = 5.00; // æœ€å¤§æˆæœ¬$5
  
  return (result) => {
    const estimatedCost = calculateTokenCost(result.usage);
    return estimatedCost > maxCost;
  };
})();

// ç»¼åˆèµ„æºé™åˆ¶
const resourceLimitStop = (result) => {
  return timeBasedStop(result) || 
         costBasedStop(result) ||
         result.usage.totalTokens > 100000;
};
```

#### å®é™…åº”ç”¨åœºæ™¯

**åœºæ™¯1: ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ**
```typescript
class ResearchReportGenerator {
  generateReport(topic: string, depth: 'basic' | 'detailed' | 'comprehensive') {
    const stopConditions = {
      basic: stepCountIs(3),
      detailed: (result) => {
        return result.text.length > 3000 || 
               result.toolCalls.length > 5;
      },
      comprehensive: (result) => {
        const hasIntroduction = result.text.includes('# å¼•è¨€');
        const hasMethodology = result.text.includes('# æ–¹æ³•è®º');
        const hasAnalysis = result.text.includes('# åˆ†æ');
        const hasConclusion = result.text.includes('# ç»“è®º');
        
        return hasIntroduction && hasMethodology && hasAnalysis && hasConclusion;
      }
    };
    
    return streamText({
      model: openai('gpt-4'),
      prompt: `ç”Ÿæˆå…³äº"${topic}"çš„${depth}ç ”ç©¶æŠ¥å‘Š`,
      tools: {
        searchLiterature: this.searchTool,
        analyzeData: this.analysisTool,
        generateChart: this.chartTool,
        citeSources: this.citationTool
      },
      stopWhen: stopConditions[depth]
    });
  }
}
```

**åœºæ™¯2: æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ**
```typescript
class ConversationalAgent {
  async chat(userMessage: string, conversationHistory: Message[]) {
    // åŸºäºå¯¹è¯çŠ¶æ€çš„åœæ­¢æ¡ä»¶
    const conversationStop = (result) => {
      // æ£€æŸ¥æ˜¯å¦ç»™å‡ºäº†æ˜ç¡®ç­”æ¡ˆ
      const hasDirectAnswer = this.detectDirectAnswer(result.text);
      
      // æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
      const needsMoreInfo = result.text.includes('éœ€è¦æ›´å¤šä¿¡æ¯') ||
                           result.text.includes('è¯·æä¾›');
      
      // æ£€æŸ¥å¯¹è¯æ˜¯å¦è¾¾åˆ°è‡ªç„¶ç»“æŸç‚¹
      const isNaturalEnd = result.text.includes('è¿˜æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©') ||
                          result.text.includes('å¸Œæœ›è¿™ä¸ªå›ç­”');
      
      return hasDirectAnswer || needsMoreInfo || isNaturalEnd;
    };
    
    return streamText({
      model: openai('gpt-4'),
      messages: conversationHistory,
      prompt: userMessage,
      tools: {
        searchKnowledge: this.knowledgeSearchTool,
        calculateResult: this.calculatorTool,
        getSystemInfo: this.systemInfoTool
      },
      stopWhen: conversationStop
    });
  }
}
```

---

## å·¥å…·è°ƒç”¨æœºåˆ¶ä¸è¿æ¥ç®¡ç†

### Q5: toolChoiceæ˜¯åœ¨å¤§æ¨¡å‹ç”Ÿæˆå‰è°ƒç”¨å·¥å…·ï¼Œè¿˜æ˜¯ç”Ÿæˆæ—¶è°ƒç”¨å·¥å…·ï¼Ÿ

**A:** toolChoiceæ˜¯**é¢„å¤„ç†é…ç½®**ï¼Œåœ¨å¤§æ¨¡å‹ç”Ÿæˆå‰ç¡®å®šå·¥å…·å¯ç”¨æ€§ï¼Œè€Œä¸æ˜¯å®æ—¶å·¥å…·è°ƒç”¨ã€‚

#### LLMä¸SDKçš„èŒè´£åˆ†å·¥

**å¤§æ¨¡å‹(LLM)çš„èƒ½åŠ›ï¼š**
- åªèƒ½è¾“å‡ºæ–‡æœ¬æµ
- ç”Ÿæˆå·¥å…·è°ƒç”¨çš„JSONæŒ‡ä»¤
- æ— æ³•ä¸»åŠ¨æš‚åœæˆ–æ¢å¤ç”Ÿæˆ
- ä¸å…·å¤‡å·¥å…·æ‰§è¡Œèƒ½åŠ›

**Vercel AI SDKçš„å°è£…åŠŸèƒ½ï¼š**
- è§£ææ–‡æœ¬æµä¸­çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤
- ä¸­æ–­æµå¼ç”Ÿæˆ
- æ‰§è¡Œå·¥å…·å¹¶ç­‰å¾…ç»“æœ
- å°†å·¥å…·ç»“æœæ³¨å…¥ä¸Šä¸‹æ–‡
- æ¢å¤ç”Ÿæˆæµç¨‹

#### å·¥å…·è°ƒç”¨æ—¶åºå›¾

```typescript
// æ—¶åºæµç¨‹ç¤ºä¾‹
async function demonstrateToolCallFlow() {
  // 1. é¢„å¤„ç†é˜¶æ®µ - toolChoiceé…ç½®
  const result = streamText({
    model: openai('gpt-4'),
    tools: {
      getWeather: tool({
        description: 'è·å–å¤©æ°”ä¿¡æ¯',
        parameters: z.object({ city: z.string() }),
        execute: async ({ city }) => getWeatherAPI(city)
      })
    },
    toolChoice: 'auto', // ğŸ“ è¿™é‡Œåªæ˜¯å‘Šè¯‰LLMæœ‰å“ªäº›å·¥å…·å¯ç”¨
    prompt: 'åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
  });

  // 2. LLMç”Ÿæˆé˜¶æ®µ - è¾“å‡ºå·¥å…·è°ƒç”¨æŒ‡ä»¤
  // LLMè¾“å‡º: "æˆ‘éœ€è¦æŸ¥è¯¢å¤©æ°”ä¿¡æ¯ <tool_call>getWeather({"city": "åŒ—äº¬"})</tool_call>"
  
  // 3. SDKè§£æå’Œæ‰§è¡Œé˜¶æ®µ
  for await (const chunk of result.textStream) {
    if (chunk.type === 'tool-call') {
      // ğŸ›‘ SDKæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œä¸­æ–­æ–‡æœ¬æµ
      console.log('æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œæš‚åœç”Ÿæˆ');
      
      // ğŸ”§ SDKæ‰§è¡Œå·¥å…·
      const toolResult = await executeToolFunction(chunk);
      
      // ğŸ”„ SDKé‡æ–°è°ƒç”¨LLMï¼ŒåŒ…å«å·¥å…·ç»“æœ
      const resumedGeneration = await continueWithToolResult(toolResult);
    }
  }
}
```

#### è¯¦ç»†æ‰§è¡Œæ—¶åº

```typescript
// å®é™…çš„æ‰§è¡Œæµç¨‹
class ToolCallExecutionFlow {
  async execute() {
    // === ç¬¬ä¸€æ¬¡LLMè°ƒç”¨ ===
    console.log('1. ç¬¬ä¸€æ¬¡LLMè°ƒç”¨');
    const response1 = await llm.generateText({
      messages: [
        { role: 'user', content: 'åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' }
      ],
      tools: [weatherTool], // toolChoiceåœ¨è¿™é‡Œç”Ÿæ•ˆ
    });
    
    console.log('LLMè¾“å‡º:', response1.text);
    // è¾“å‡º: "æˆ‘éœ€è¦æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”ä¿¡æ¯"
    // å·¥å…·è°ƒç”¨: [{ type: "function", function: { name: "getWeather", arguments: '{"city":"åŒ—äº¬"}' }}]
    
    // === SDKå·¥å…·æ‰§è¡Œé˜¶æ®µ ===
    console.log('2. SDKæ‰§è¡Œå·¥å…·');
    const toolResult = await this.executeWeatherTool({ city: 'åŒ—äº¬' });
    console.log('å·¥å…·ç»“æœ:', toolResult);
    // ç»“æœ: { temperature: 25, condition: 'æ™´å¤©', humidity: 60 }
    
    // === ç¬¬äºŒæ¬¡LLMè°ƒç”¨ï¼ˆåŒ…å«å·¥å…·ç»“æœï¼‰===
    console.log('3. ç¬¬äºŒæ¬¡LLMè°ƒç”¨ï¼ˆåŒ…å«å·¥å…·ç»“æœï¼‰');
    const response2 = await llm.generateText({
      messages: [
        { role: 'user', content: 'åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' },
        { role: 'assistant', content: response1.text, tool_calls: response1.toolCalls },
        { role: 'tool', content: JSON.stringify(toolResult) }
      ]
    });
    
    console.log('æœ€ç»ˆå›ç­”:', response2.text);
    // è¾“å‡º: "æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©æ™´å¤©ï¼Œæ°”æ¸©25Â°Cï¼Œæ¹¿åº¦60%"
  }
}
```

---

### Q6: é€šè¿‡chunk-typeèƒ½å¦è®©å¤§æ¨¡å‹æš‚åœç”Ÿæˆï¼Œç­‰å¾…å·¥å…·è¿”å›åç»§ç»­ç”Ÿæˆï¼Ÿ

**A:** æ˜¯çš„ï¼Œä½†è¿™æ˜¯**SDKå†…éƒ¨çš„æµç®¡ç†æœºåˆ¶**ï¼Œä¸æ˜¯å¤§æ¨¡å‹æœ¬èº«çš„èƒ½åŠ›ã€‚

#### ä¸­æ–­-ç­‰å¾…-æ¢å¤æœºåˆ¶

```typescript
// SDKå†…éƒ¨çš„æµå¤„ç†æœºåˆ¶
class StreamProcessor {
  async processStream(llmStream: ReadableStream) {
    for await (const chunk of llmStream) {
      if (chunk.type === 'tool-call') {
        // 1. SDKæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ - æš‚åœæµ
        await this.pauseStream();
        console.log('ğŸ›‘ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œæš‚åœç”Ÿæˆæµ');
        
        // 2. SDKæ‰§è¡Œå·¥å…·
        const toolResult = await this.executeTool(chunk.toolCall);
        console.log('ğŸ”§ å·¥å…·æ‰§è¡Œå®Œæˆ:', toolResult);
        
        // 3. SDKåˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡
        const newContext = this.injectToolResult(context, toolResult);
        console.log('ğŸ“ å·¥å…·ç»“æœå·²æ³¨å…¥ä¸Šä¸‹æ–‡');
        
        // 4. SDKé‡æ–°å¯åŠ¨LLMç”Ÿæˆ
        const resumedStream = await this.resumeGeneration(newContext);
        console.log('ğŸ”„ é‡æ–°å¯åŠ¨ç”Ÿæˆæµ');
        
        // 5. ç»§ç»­å¤„ç†æ–°æµ
        return this.processStream(resumedStream);
      }
    }
  }
}
```

#### å®é™…æ‰§è¡Œç¤ºä¾‹

```typescript
// ç”¨æˆ·æ„ŸçŸ¥çš„è¿ç»­ä½“éªŒ vs å®é™…çš„æ‰§è¡Œè¿‡ç¨‹
async function toolCallExample() {
  const result = streamText({
    model: openai('gpt-4'),
    tools: { getWeather, getNews },
    prompt: 'åŒ—äº¬ä»Šå¤©å¤©æ°”å’Œæ–°é—»'
  });

  // ç”¨æˆ·çœ‹åˆ°çš„æµå¼è¾“å‡º:
  // "è®©æˆ‘ä¸ºæ‚¨æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”å’Œæ–°é—»ä¿¡æ¯..."
  // [å·¥å…·è°ƒç”¨æŒ‡ç¤ºå™¨] æ­£åœ¨æŸ¥è¯¢å¤©æ°”...
  // "æ ¹æ®æŸ¥è¯¢ï¼ŒåŒ—äº¬ä»Šå¤©æ™´å¤©25Â°C..."
  // [å·¥å…·è°ƒç”¨æŒ‡ç¤ºå™¨] æ­£åœ¨è·å–æ–°é—»...
  // "ä»Šæ—¥åŒ—äº¬æ–°é—»æ‘˜è¦ï¼š..."

  // å®é™…çš„åº•å±‚æ‰§è¡Œ:
  console.log('=== å®é™…æ‰§è¡Œæµç¨‹ ===');
  
  // ç¬¬1æ¬¡LLMè°ƒç”¨
  console.log('1. LLMç”Ÿæˆ: "è®©æˆ‘ä¸ºæ‚¨æŸ¥è¯¢ä¿¡æ¯"');
  console.log('   å·¥å…·è°ƒç”¨: getWeather({city: "åŒ—äº¬"})');
  
  // è¿æ¥ä¸­æ–­ + å·¥å…·æ‰§è¡Œ
  console.log('2. ğŸ›‘ ä¸­æ–­LLMè¿æ¥');
  console.log('3. ğŸ”§ æ‰§è¡Œå¤©æ°”API: ç»“æœ={temp: 25, condition: "æ™´"}');
  
  // ç¬¬2æ¬¡LLMè°ƒç”¨
  console.log('4. ğŸ”„ é‡æ–°è¿æ¥LLMï¼Œä¸Šä¸‹æ–‡åŒ…å«å¤©æ°”ç»“æœ');
  console.log('5. LLMç”Ÿæˆ: "æ ¹æ®æŸ¥è¯¢ï¼ŒåŒ—äº¬ä»Šå¤©æ™´å¤©25Â°Cï¼Œç°åœ¨æŸ¥è¯¢æ–°é—»"');
  console.log('   å·¥å…·è°ƒç”¨: getNews({location: "åŒ—äº¬"})');
  
  // å†æ¬¡ä¸­æ–­ + å·¥å…·æ‰§è¡Œ
  console.log('6. ğŸ›‘ å†æ¬¡ä¸­æ–­LLMè¿æ¥');
  console.log('7. ğŸ”§ æ‰§è¡Œæ–°é—»API: ç»“æœ=[{title: "æ–°é—»1"}, {title: "æ–°é—»2"}]');
  
  // ç¬¬3æ¬¡LLMè°ƒç”¨
  console.log('8. ğŸ”„ ç¬¬ä¸‰æ¬¡è¿æ¥LLMï¼Œä¸Šä¸‹æ–‡åŒ…å«æ‰€æœ‰ç»“æœ');
  console.log('9. LLMç”Ÿæˆ: "ä»Šæ—¥åŒ—äº¬æ–°é—»æ‘˜è¦ï¼šæ–°é—»1, æ–°é—»2"');
}
```

---

### Q7: è¿™ç§è¿æ¥ä¸­æ–­é‡å»ºæœºåˆ¶æ˜¯å¦ä¼šå¢åŠ Tokenæ¶ˆè€—ï¼Ÿ

**A:** **æ˜¯çš„ï¼Œä¼šæ˜¾è‘—å¢åŠ Tokenæ¶ˆè€—**ï¼Œå› ä¸ºæ¯æ¬¡é‡æ–°è¿æ¥éƒ½è¦å‘é€å®Œæ•´çš„ä¸Šä¸‹æ–‡å†å²ã€‚

#### Tokenæ¶ˆè€—åˆ†æ

**é‡å¤ä¸Šä¸‹æ–‡å‘é€ï¼š**
```typescript
// ç¬¬ä¸€æ¬¡è°ƒç”¨çš„ä¸Šä¸‹æ–‡
const call1_context = {
  messages: [
    { role: 'user', content: 'ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' },
    // å‡è®¾è¿˜æœ‰å…¶ä»–å†å²æ¶ˆæ¯ = 1000 tokens
  ]
};
// Tokenæ¶ˆè€—: 1000 tokens

// å·¥å…·è°ƒç”¨åç¬¬äºŒæ¬¡è°ƒç”¨çš„ä¸Šä¸‹æ–‡  
const call2_context = {
  messages: [
    { role: 'user', content: 'ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' },        // é‡å¤å‘é€
    { role: 'assistant', content: 'æˆ‘éœ€è¦æŸ¥è¯¢å¤©æ°”', tool_calls: [...] }, // æ–°å¢
    { role: 'tool', content: 'åŒ—äº¬ä»Šå¤©æ™´å¤©25Â°C' },              // å·¥å…·ç»“æœ
    // æ‰€æœ‰å†å²æ¶ˆæ¯éƒ½è¦é‡æ–°å‘é€
  ]
};
// Tokenæ¶ˆè€—: 1000 + 200 = 1200 tokens
```

#### æˆæœ¬å€å¢ç¤ºä¾‹

```typescript
// å®é™…çš„æˆæœ¬è®¡ç®—ç¤ºä¾‹
class TokenCostAnalysis {
  calculateToolCallCost() {
    // å‡è®¾åŸºç¡€å¯¹è¯ä¸Šä¸‹æ–‡ = 1000 tokens
    const baseContext = 1000;
    
    console.log('=== åŒ…å«3ä¸ªå·¥å…·è°ƒç”¨çš„å¯¹è¯æˆæœ¬ ===');
    
    // ç¬¬1æ¬¡è°ƒç”¨ï¼ˆæ— å·¥å…·ç»“æœï¼‰
    const call1_tokens = baseContext; // 1000 tokens
    console.log(`è°ƒç”¨1: ${call1_tokens} tokens`);
    
    // ç¬¬2æ¬¡è°ƒç”¨ï¼ˆåŒ…å«å·¥å…·1ç»“æœï¼‰
    const tool1_result = 200; // å·¥å…·1è¿”å›200 tokensçš„æ•°æ®
    const call2_tokens = baseContext + tool1_result; // 1200 tokens
    console.log(`è°ƒç”¨2: ${call2_tokens} tokens (åŒ…å«å·¥å…·1ç»“æœ)`);
    
    // ç¬¬3æ¬¡è°ƒç”¨ï¼ˆåŒ…å«å·¥å…·1+2ç»“æœï¼‰
    const tool2_result = 300; // å·¥å…·2è¿”å›300 tokensçš„æ•°æ®
    const call3_tokens = baseContext + tool1_result + tool2_result; // 1500 tokens
    console.log(`è°ƒç”¨3: ${call3_tokens} tokens (åŒ…å«å·¥å…·1+2ç»“æœ)`);
    
    // ç¬¬4æ¬¡è°ƒç”¨ï¼ˆåŒ…å«å·¥å…·1+2+3ç»“æœï¼‰
    const tool3_result = 150; // å·¥å…·3è¿”å›150 tokensçš„æ•°æ®
    const call4_tokens = baseContext + tool1_result + tool2_result + tool3_result; // 1650 tokens
    console.log(`è°ƒç”¨4: ${call4_tokens} tokens (åŒ…å«æ‰€æœ‰å·¥å…·ç»“æœ)`);
    
    const totalTokens = call1_tokens + call2_tokens + call3_tokens + call4_tokens;
    console.log(`æ€»æ¶ˆè€—: ${totalTokens} tokens`);
    console.log(`vs å•æ¬¡è°ƒç”¨: ${baseContext} tokens`);
    console.log(`å€æ•°: ${(totalTokens / baseContext).toFixed(1)}x`);
    
    // æˆæœ¬è®¡ç®—ï¼ˆå‡è®¾$0.01/1000 tokensï¼‰
    const costPerToken = 0.01 / 1000;
    const totalCost = totalTokens * costPerToken;
    const singleCallCost = baseContext * costPerToken;
    
    console.log(`å®é™…æˆæœ¬: $${totalCost.toFixed(4)} vs $${singleCallCost.toFixed(4)}`);
  }
}

// è¾“å‡ºç»“æœ:
// è°ƒç”¨1: 1000 tokens
// è°ƒç”¨2: 1200 tokens (åŒ…å«å·¥å…·1ç»“æœ)
// è°ƒç”¨3: 1500 tokens (åŒ…å«å·¥å…·1+2ç»“æœ)
// è°ƒç”¨4: 1650 tokens (åŒ…å«æ‰€æœ‰å·¥å…·ç»“æœ)
// æ€»æ¶ˆè€—: 5350 tokens
// vs å•æ¬¡è°ƒç”¨: 1000 tokens
// å€æ•°: 5.4x
// å®é™…æˆæœ¬: $0.0535 vs $0.0100
```

#### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

ä¼ä¸šçº§åº”ç”¨é€šå¸¸é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥é™ä½æˆæœ¬ï¼š

```typescript
// 1. æ‰¹é‡å·¥å…·è°ƒç”¨
const batchToolStrategy = streamText({
  model: openai('gpt-4'),
  tools: { tool1, tool2, tool3 },
  toolChoice: 'auto',
  prompt: 'åŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡',
  // é…ç½®ä¸€æ¬¡æ€§è°ƒç”¨å¤šä¸ªå·¥å…·
  maxToolRoundtrips: 1 // é™åˆ¶å·¥å…·è°ƒç”¨è½®æ¬¡
});

// 2. ä¸Šä¸‹æ–‡å‹ç¼©
class ContextCompressor {
  async compressHistory(messages: Message[]): Promise<Message[]> {
    // æ™ºèƒ½æ€»ç»“å†å²å¯¹è¯
    const summary = await this.summarizeConversation(messages.slice(0, -5));
    return [
      { role: 'system', content: `å¯¹è¯æ‘˜è¦: ${summary}` },
      ...messages.slice(-5) // ä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯
    ];
  }
}

// 3. æ£€æŸ¥ç‚¹æœºåˆ¶ï¼ˆç±»ä¼¼LangGraphï¼‰
class CheckpointSystem {
  async saveCheckpoint(conversationState: ConversationState) {
    await this.db.save('conversation_checkpoint', conversationState);
  }
  
  async loadCheckpoint(conversationId: string): Promise<ConversationState> {
    return await this.db.load('conversation_checkpoint', conversationId);
  }
}
```

**æ€»ç»“ï¼š**
- âœ… æµç•…çš„ç”¨æˆ·ä½“éªŒï¼Œæ„Ÿè§‰åƒè¿ç»­å¯¹è¯
- âŒ èƒŒåæ˜¯å¤šæ¬¡LLMè°ƒç”¨ï¼Œæˆæœ¬æ˜¾è‘—å¢åŠ 
- ğŸ¯ ä¼ä¸šåº”ç”¨éœ€è¦åœ¨ç”¨æˆ·ä½“éªŒå’Œæˆæœ¬ä¹‹é—´æƒè¡¡
- ğŸ”§ å¯é€šè¿‡æ‰¹é‡è°ƒç”¨ã€ä¸Šä¸‹æ–‡å‹ç¼©ã€æ£€æŸ¥ç‚¹ç­‰ç­–ç•¥ä¼˜åŒ–

---

## UIMessageæ¶æ„ä¸è®¾è®¡

### Q8: UIMessageæ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå«åšUI Messageï¼Ÿ

**A:** UIMessageæ˜¯Vercel AI SDKä¸“é—¨ä¸º**å‰ç«¯UIæ¸²æŸ“**è€Œè®¾è®¡çš„æ¶ˆæ¯æ ¼å¼ï¼Œä¸ç”¨äºLLMäº¤äº’çš„ModelMessageå®Œå…¨åˆ†ç¦»ã€‚

#### è®¾è®¡å“²å­¦ï¼šå‰ç«¯ä¼˜å…ˆ

UIMessageçš„æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯**"ä¸ºUIè€Œç”Ÿ"**ï¼Œå®ƒä¸æ˜¯ä¸ºäº†ä¸LLMå¯¹è¯ï¼Œè€Œæ˜¯ä¸ºäº†åœ¨å‰ç«¯å®Œç¾å‘ˆç°AIäº¤äº’è¿‡ç¨‹ã€‚

#### ä¸¤ç§Messageçš„èŒè´£åˆ†ç¦»

**ModelMessageï¼ˆåç«¯LLMäº¤äº’ï¼‰**
```typescript
// å‘é€ç»™LLMçš„ç®€åŒ–æ¶ˆæ¯æ ¼å¼
type ModelMessage = 
  | SystemModelMessage    // ç³»ç»ŸæŒ‡ä»¤
  | UserModelMessage      // ç”¨æˆ·è¾“å…¥
  | AssistantModelMessage // AIå›å¤
  | ToolModelMessage;     // å·¥å…·ç»“æœ

// ç¤ºä¾‹
{
  role: "user",
  content: "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
}
```
- **ç›®çš„**: ä¸LLMè¿›è¡Œå¯¹è¯äº¤äº’
- **ä¼˜åŒ–**: Tokenæ•ˆç‡å’ŒLLMç†è§£
- **ç»“æ„**: ç®€å•çš„è§’è‰²+å†…å®¹æ ¼å¼

**UIMessageï¼ˆå‰ç«¯UIæ¸²æŸ“ï¼‰**
```typescript
// ä¸ºUIç»„ä»¶ä¼˜åŒ–çš„å¯Œåª’ä½“æ¶ˆæ¯æ ¼å¼
interface UIMessage<METADATA, DATA_PARTS, TOOLS> {
  id: string;                    // å”¯ä¸€æ ‡è¯†
  role: 'system' | 'user' | 'assistant';
  metadata?: METADATA;           // è‡ªå®šä¹‰å…ƒæ•°æ®
  parts: Array<UIMessagePart>;   // ç»„ä»¶åŒ–çš„éƒ¨åˆ†
}

// ç¤ºä¾‹
{
  id: "msg_123",
  role: "assistant", 
  metadata: { timestamp: "2025-01-27T10:00:00Z" },
  parts: [
    { type: "text", text: "è®©æˆ‘æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”", state: "done" },
    { 
      type: "tool-weather", 
      toolCallId: "call_456",
      state: "output-available",
      input: { city: "åŒ—äº¬" },
      output: { temperature: 25, condition: "æ™´å¤©" }
    },
    { type: "text", text: "åŒ—äº¬ä»Šå¤©æ™´å¤©ï¼Œæ°”æ¸©25Â°C", state: "done" }
  ]
}
```
- **ç›®çš„**: ä¸ºå‰ç«¯UIç»„ä»¶æä¾›å®Œæ•´æ¸²æŸ“ä¿¡æ¯
- **ä¼˜åŒ–**: ç”¨æˆ·ä½“éªŒå’Œç•Œé¢äº¤äº’
- **ç»“æ„**: ä¸°å¯Œçš„partsç³»ç»Ÿï¼Œæ”¯æŒå¤šç§UIå…ƒç´ 

#### ä¸ºä»€ä¹ˆå«"UI Message"ï¼Ÿ

1. **ğŸ¯ ä¸“ä¸ºUIè®¾è®¡**: ä¸æ˜¯ä¸ºLLMäº¤äº’ï¼Œè€Œæ˜¯ä¸ºå‰ç«¯æ¸²æŸ“è€Œç”Ÿ
2. **ğŸ§© ç»„ä»¶åŒ–æ¶æ„**: æ¯ä¸ªpartå¯¹åº”ä¸€ä¸ªUIç»„ä»¶
3. **âš¡ å®æ—¶ä½“éªŒ**: æ”¯æŒæµå¼UIçŠ¶æ€æ›´æ–°
4. **ğŸ¨ ä¸°å¯Œè¡¨ç°**: åŒ…å«UIæ¸²æŸ“æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯

---

### Q9: UIMessageæœ‰å“ªäº›ç±»å‹å®šä¹‰å’ŒPartç»„ä»¶ï¼Ÿ

**A:** UIMessageé‡‡ç”¨**ç»„ä»¶åŒ–çš„Partsæ¶æ„**ï¼Œæ¯ä¸ªpartå¯¹åº”ä¸åŒçš„UIç»„ä»¶ç±»å‹ã€‚

#### æ ¸å¿ƒæ¥å£å®šä¹‰

```typescript
interface UIMessage<
  METADATA = unknown,
  DATA_PARTS extends UIDataTypes = UIDataTypes,
  TOOLS extends UITools = UITools,
> {
  /**
   * æ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦
   */
  id: string;

  /**
   * æ¶ˆæ¯çš„è§’è‰²
   */
  role: 'system' | 'user' | 'assistant';

  /**
   * æ¶ˆæ¯çš„å…ƒæ•°æ®ï¼ˆå¯è‡ªå®šä¹‰ç±»å‹ï¼‰
   */
  metadata?: METADATA;

  /**
   * æ¶ˆæ¯çš„ç»„ä»¶éƒ¨åˆ†ï¼Œç”¨äºUIæ¸²æŸ“
   */
  parts: Array<UIMessagePart<DATA_PARTS, TOOLS>>;
}
```

#### å®Œæ•´çš„Partç±»å‹ç³»ç»Ÿ

**1. TextUIPart - æ–‡æœ¬ç»„ä»¶**
```typescript
type TextUIPart = {
  type: 'text';
  
  /**
   * æ–‡æœ¬å†…å®¹
   */
  text: string;

  /**
   * æ–‡æœ¬çŠ¶æ€ - æ”¯æŒæµå¼æ¸²æŸ“
   */
  state?: 'streaming' | 'done';

  /**
   * æä¾›å•†å…ƒæ•°æ®
   */
  providerMetadata?: ProviderMetadata;
};

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "text",
  text: "æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯...",
  state: "streaming"  // UIæ˜¾ç¤ºæ‰“å­—æœºæ•ˆæœ
}
```

**2. ReasoningUIPart - æ¨ç†è¿‡ç¨‹ç»„ä»¶**
```typescript
type ReasoningUIPart = {
  type: 'reasoning';
  
  /**
   * æ¨ç†æ–‡æœ¬å†…å®¹
   */
  text: string;

  /**
   * æ¨ç†çŠ¶æ€
   */
  state?: 'streaming' | 'done';

  /**
   * æä¾›å•†å…ƒæ•°æ®
   */
  providerMetadata?: ProviderMetadata;
};

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "reasoning",
  text: "ç”¨æˆ·è¯¢é—®å¤©æ°”ï¼Œæˆ‘éœ€è¦è°ƒç”¨å¤©æ°”APIè·å–å®æ—¶ä¿¡æ¯",
  state: "done"
}
```

**3. ToolUIPart - å·¥å…·è°ƒç”¨ç»„ä»¶**
```typescript
type ToolUIPart<TOOLS extends UITools = UITools> = ValueOf<{
  [NAME in keyof TOOLS & string]: {
    type: `tool-${NAME}`;  // ä¾‹å¦‚: tool-weather, tool-search
    toolCallId: string;
  } & (
    | {
        state: 'input-streaming';           // å‚æ•°è¾“å…¥ä¸­
        input: DeepPartial<TOOLS[NAME]['input']> | undefined;
        providerExecuted?: boolean;
        output?: never;
        errorText?: never;
      }
    | {
        state: 'input-available';          // å‚æ•°å‡†å¤‡å®Œæˆ
        input: TOOLS[NAME]['input'];
        providerExecuted?: boolean;
        output?: never;
        errorText?: never;
        callProviderMetadata?: ProviderMetadata;
      }
    | {
        state: 'output-available';         // å·¥å…·æ‰§è¡Œå®Œæˆ
        input: TOOLS[NAME]['input'];
        output: TOOLS[NAME]['output'];
        errorText?: never;
        providerExecuted?: boolean;
        callProviderMetadata?: ProviderMetadata;
        preliminary?: boolean;              // æ˜¯å¦ä¸ºé¢„å¤‡ç»“æœ
      }
    | {
        state: 'output-error';             // å·¥å…·æ‰§è¡Œé”™è¯¯
        input: TOOLS[NAME]['input'] | undefined;
        rawInput?: unknown;
        output?: never;
        errorText: string;
        providerExecuted?: boolean;
        callProviderMetadata?: ProviderMetadata;
      }
  );
}>;

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "tool-weather",
  toolCallId: "call_123",
  state: "output-available",
  input: { city: "åŒ—äº¬", unit: "celsius" },
  output: { 
    temperature: 25, 
    condition: "æ™´å¤©",
    humidity: 60,
    windSpeed: 15
  }
}
```

**4. DynamicToolUIPart - åŠ¨æ€å·¥å…·ç»„ä»¶**
```typescript
type DynamicToolUIPart = {
  type: 'dynamic-tool';
  toolName: string;      // å·¥å…·åç§°
  toolCallId: string;
} & (
  | {
      state: 'input-streaming';
      input: unknown | undefined;
      output?: never;
      errorText?: never;
    }
  | {
      state: 'input-available';
      input: unknown;
      output?: never;
      errorText?: never;
      callProviderMetadata?: ProviderMetadata;
    }
  | {
      state: 'output-available';
      input: unknown;
      output: unknown;
      errorText?: never;
      callProviderMetadata?: ProviderMetadata;
      preliminary?: boolean;
    }
  | {
      state: 'output-error';
      input: unknown;
      output?: never;
      errorText: string;
      callProviderMetadata?: ProviderMetadata;
    }
);

// ä½¿ç”¨ç¤ºä¾‹ - è¿è¡Œæ—¶åŠ¨æ€å·¥å…·
{
  type: "dynamic-tool",
  toolName: "custom_api_call",
  toolCallId: "call_456",
  state: "input-available",
  input: { endpoint: "/api/data", method: "GET" }
}
```

**5. FileUIPart - æ–‡ä»¶ç»„ä»¶**
```typescript
type FileUIPart = {
  type: 'file';

  /**
   * IANAåª’ä½“ç±»å‹
   * @see https://www.iana.org/assignments/media-types/media-types.xhtml
   */
  mediaType: string;

  /**
   * å¯é€‰çš„æ–‡ä»¶å
   */
  filename?: string;

  /**
   * æ–‡ä»¶URLï¼ˆå¯ä»¥æ˜¯æ‰˜ç®¡URLæˆ–Data URLï¼‰
   */
  url: string;

  /**
   * æä¾›å•†å…ƒæ•°æ®
   */
  providerMetadata?: ProviderMetadata;
};

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "file",
  mediaType: "image/png",
  filename: "weather_chart.png",
  url: "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
}
```

**6. SourceUrlUIPart - æ¥æºé“¾æ¥ç»„ä»¶**
```typescript
type SourceUrlUIPart = {
  type: 'source-url';
  sourceId: string;      // æ¥æºæ ‡è¯†
  url: string;           // æ¥æºURL
  title?: string;        // æ¥æºæ ‡é¢˜
  providerMetadata?: ProviderMetadata;
};

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "source-url",
  sourceId: "src_123",
  url: "https://weather.com/beijing",
  title: "åŒ—äº¬å¤©æ°” - Weather.com"
}
```

**7. SourceDocumentUIPart - æ–‡æ¡£æ¥æºç»„ä»¶**
```typescript
type SourceDocumentUIPart = {
  type: 'source-document';
  sourceId: string;      // æ–‡æ¡£æ ‡è¯†
  mediaType: string;     // æ–‡æ¡£ç±»å‹
  title: string;         // æ–‡æ¡£æ ‡é¢˜
  filename?: string;     // æ–‡ä»¶å
  providerMetadata?: ProviderMetadata;
};

// ä½¿ç”¨ç¤ºä¾‹
{
  type: "source-document",
  sourceId: "doc_456",
  mediaType: "application/pdf",
  title: "æ°”è±¡æ•°æ®æŠ¥å‘Š",
  filename: "weather_report_2025.pdf"
}
```

**8. DataUIPart - è‡ªå®šä¹‰æ•°æ®ç»„ä»¶**
```typescript
type DataUIPart<DATA_TYPES extends UIDataTypes> = ValueOf<{
  [NAME in keyof DATA_TYPES & string]: {
    type: `data-${NAME}`;  // ä¾‹å¦‚: data-chart, data-table
    id?: string;
    data: DATA_TYPES[NAME];
  };
}>;

// ä½¿ç”¨ç¤ºä¾‹ - è‡ªå®šä¹‰å›¾è¡¨æ•°æ®
{
  type: "data-chart",
  id: "chart_789",
  data: {
    chartType: "line",
    title: "æ¸©åº¦è¶‹åŠ¿",
    dataPoints: [
      { time: "09:00", temperature: 22 },
      { time: "12:00", temperature: 25 },
      { time: "15:00", temperature: 28 }
    ]
  }
}
```

**9. StepStartUIPart - æ­¥éª¤åˆ†éš”ç»„ä»¶**
```typescript
type StepStartUIPart = {
  type: 'step-start';
};

// ä½¿ç”¨ç¤ºä¾‹ - å¤šæ­¥éª¤ä»»åŠ¡çš„åˆ†éš”ç¬¦
{
  type: "step-start"  // UIæ¸²æŸ“ä¸ºæ­¥éª¤åˆ†éš”çº¿
}
```

#### å®é™…UIç»„ä»¶æ¸²æŸ“ç¤ºä¾‹

```tsx
// Reactç»„ä»¶ä¸­ä½¿ç”¨UIMessage
function MessageRenderer({ message }: { message: UIMessage }) {
  return (
    <div className="message">
      <div className="message-header">
        <span className="role">{message.role}</span>
        <span className="timestamp">{message.metadata?.timestamp}</span>
      </div>
      
      <div className="message-parts">
        {message.parts.map((part, index) => {
          switch (part.type) {
            case 'text':
              return (
                <TextComponent 
                  key={index}
                  text={part.text} 
                  streaming={part.state === 'streaming'} 
                />
              );
              
            case 'tool-weather':
              return (
                <WeatherToolComponent
                  key={index}
                  toolCall={part}
                  loading={part.state === 'input-streaming'}
                  error={part.state === 'output-error'}
                />
              );
              
            case 'file':
              return (
                <FileComponent
                  key={index}
                  url={part.url}
                  mediaType={part.mediaType}
                  filename={part.filename}
                />
              );
              
            case 'reasoning':
              return (
                <ReasoningComponent
                  key={index}
                  text={part.text}
                  collapsible={true}
                />
              );
              
            case 'step-start':
              return <StepSeparator key={index} />;
              
            default:
              return null;
          }
        })}
      </div>
    </div>
  );
}
```

#### æµå¼çŠ¶æ€æ›´æ–°æœºåˆ¶

UIMessageæ”¯æŒå®æ—¶çŠ¶æ€æ›´æ–°ï¼Œè®©UIèƒ½å¤Ÿæµç•…æ˜¾ç¤ºAIå¤„ç†è¿‡ç¨‹ï¼š

```typescript
// æµå¼æ›´æ–°ç¤ºä¾‹
const messageState = {
  id: "msg_123",
  role: "assistant",
  parts: [
    // 1. å¼€å§‹æ—¶æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
    { type: "text", text: "è®©æˆ‘æ€è€ƒä¸€ä¸‹...", state: "streaming" },
    
    // 2. å·¥å…·è°ƒç”¨å¼€å§‹
    { 
      type: "tool-weather", 
      toolCallId: "call_456",
      state: "input-streaming",     // UIæ˜¾ç¤º"æ­£åœ¨è¾“å…¥å‚æ•°"
      input: { city: "åŒ—" }         // éƒ¨åˆ†å‚æ•°
    },
    
    // 3. å·¥å…·å‚æ•°å®Œæˆ
    { 
      type: "tool-weather",
      state: "input-available",     // UIæ˜¾ç¤º"å‚æ•°å‡†å¤‡å®Œæˆ" 
      input: { city: "åŒ—äº¬" }
    },
    
    // 4. å·¥å…·æ‰§è¡Œå®Œæˆ
    {
      type: "tool-weather",
      state: "output-available",    // UIæ˜¾ç¤ºæ‰§è¡Œç»“æœ
      input: { city: "åŒ—äº¬" },
      output: { temperature: 25, condition: "æ™´å¤©" }
    },
    
    // 5. æœ€ç»ˆæ–‡æœ¬å›å¤
    { type: "text", text: "æ ¹æ®æŸ¥è¯¢ï¼ŒåŒ—äº¬ä»Šå¤©æ™´å¤©25Â°C", state: "done" }
  ]
};
```

è¿™ç§è®¾è®¡è®©å¼€å‘è€…èƒ½å¤Ÿæ„å»º**æ—¢é«˜æ•ˆåˆç¾è§‚**çš„AIåº”ç”¨ç•Œé¢ï¼Œå®ç°äº†åç«¯LLMäº¤äº’ä¸å‰ç«¯UIæ¸²æŸ“çš„å®Œç¾åˆ†ç¦»ã€‚

---

*æœ€åæ›´æ–°æ—¶é—´: 2025-01-27*

## ğŸ“ æ”¯æŒè”ç³»

å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- [Vercel AI SDK å®˜æ–¹æ–‡æ¡£](https://sdk.vercel.ai/docs)
- [æŠ€æœ¯åˆ†ææ–‡æ¡£](./Vercel-AI-SDKæŠ€æœ¯åˆ†æ.md)
- æäº¤Issueåˆ°æœ¬é¡¹ç›®çš„GitHubä»“åº“