# ä¸åŒæ¡†æ¶å¦‚ä½•å®ç°æ¶ˆæ¯å†å²ç®¡ç†ï¼Ÿ

## é—®é¢˜åˆ†æ

**æ¶ˆæ¯å†å²ç®¡ç†**æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ï¼Œå®ƒå†³å®šäº†æ™ºèƒ½ä½“å¦‚ä½•ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡ã€å®ç°è¿ç»­äº¤äº’ã€ä¼˜åŒ–æ€§èƒ½ï¼Œä»¥åŠæ”¯æŒå¤æ‚çš„å¤šè½®å¯¹è¯åœºæ™¯ã€‚ä¸åŒæ¡†æ¶é‡‡ç”¨äº†å„è‡ªç‹¬ç‰¹çš„è®¾è®¡ç†å¿µå’ŒæŠ€æœ¯å®ç°ã€‚

## å„æ¡†æ¶æ¶ˆæ¯å†å²ç®¡ç†å¯¹æ¯”

| æ¡†æ¶ | å­˜å‚¨æœºåˆ¶ | æŒä¹…åŒ–æ–¹æ¡ˆ | ä¸Šä¸‹æ–‡ç®¡ç† | æ€§èƒ½ä¼˜åŒ– | å¤æ‚åº¦ |
|------|----------|-----------|-----------|----------|--------|
| **LangGraph** | MessagesState + æ£€æŸ¥ç‚¹ | SQLite/PostgreSQL | è‡ªåŠ¨ç´¯ç§¯ + æ£€æŸ¥ç‚¹ | çŠ¶æ€å‹ç¼© + åˆ†æ”¯ | ä½ |
| **ADK** | InvocationContext + ä¼šè¯ | ä¼šè¯çŠ¶æ€ + äº‹ä»¶æµ | æ™ºèƒ½ä½“ç»§æ‰¿ | é™æ€æŒ‡ä»¤ç¼“å­˜ | ä¸­ |
| **Vercel AI SDK** | æµå¼çŠ¶æ€ + å†…å­˜ | è‡ªå®šä¹‰å­˜å‚¨ | æ‰‹åŠ¨ç®¡ç† | æµå¼ä¼ è¾“ | ä¸­ |
| **AG-UI** | ReactçŠ¶æ€ + Hook | æµè§ˆå™¨å­˜å‚¨ | ç»„ä»¶çŠ¶æ€ | è™šæ‹ŸåŒ–æ¸²æŸ“ | ä½ |

## è¯¦ç»†æŠ€æœ¯åˆ†æ

### 1. LangGraph - è‡ªåŠ¨åŒ–æ¶ˆæ¯çŠ¶æ€ç®¡ç†

LangGraphé€šè¿‡**MessagesState**å’Œ**add_messages**æœºåˆ¶å®ç°äº†æœ€å…ˆè¿›çš„æ¶ˆæ¯å†å²ç®¡ç†ã€‚

#### æ ¸å¿ƒæ¶ˆæ¯çŠ¶æ€å®šä¹‰
```python
from typing import Annotated
from langgraph.graph import MessagesState, add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

class ConversationState(MessagesState):
    """æ‰©å±•çš„å¯¹è¯çŠ¶æ€"""
    # è‡ªåŠ¨æ¶ˆæ¯ç®¡ç†
    messages: Annotated[list[BaseMessage], add_messages]

    # é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    conversation_id: str
    user_id: str
    session_metadata: dict

    # æ¶ˆæ¯ç»Ÿè®¡å’Œç®¡ç†
    total_tokens: int = 0
    last_activity: datetime = None
    conversation_summary: str = ""
```

#### è‡ªåŠ¨æ¶ˆæ¯ç´¯ç§¯æœºåˆ¶
```python
def chat_node(state: ConversationState) -> dict:
    """èŠå¤©èŠ‚ç‚¹ - è‡ªåŠ¨å¤„ç†æ¶ˆæ¯å†å²"""

    # LangGraphè‡ªåŠ¨ç®¡ç†æ¶ˆæ¯å†å²
    # state["messages"] åŒ…å«å®Œæ•´çš„å¯¹è¯å†å²
    messages = state["messages"]

    # ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ¶ˆæ¯æ ¼å¼åŒ–å’Œç´¯ç§¯
    response = llm.invoke(messages)

    # è¿”å›æ–°æ¶ˆæ¯ï¼ŒLangGraphè‡ªåŠ¨æ·»åŠ åˆ°å†å²ä¸­
    return {
        "messages": [response],  # è‡ªåŠ¨appendåˆ°ç°æœ‰messages
        "total_tokens": state["total_tokens"] + count_tokens(response),
        "last_activity": datetime.now()
    }

def user_input_node(state: ConversationState) -> dict:
    """ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹"""
    user_message = HumanMessage(content=get_user_input())

    # è‡ªåŠ¨æ·»åŠ åˆ°æ¶ˆæ¯å†å²
    return {"messages": [user_message]}
```

#### æ£€æŸ¥ç‚¹æŒä¹…åŒ–æœºåˆ¶
```python
from langgraph.checkpoint.sqlite import SqliteSaver

class ConversationManager:
    def __init__(self, db_path: str):
        self.checkpointer = SqliteSaver(db_path)
        self.graph = self._build_conversation_graph()

    def _build_conversation_graph(self):
        """æ„å»ºå¯¹è¯å›¾"""
        workflow = StateGraph(ConversationState)

        workflow.add_node("user_input", user_input_node)
        workflow.add_node("assistant", chat_node)
        workflow.add_node("summarizer", summary_node)

        # ç¼–è¯‘æ—¶å¯ç”¨æ£€æŸ¥ç‚¹
        return workflow.compile(checkpointer=self.checkpointer)

    async def continue_conversation(self, user_input: str, conversation_id: str):
        """ç»§ç»­ç°æœ‰å¯¹è¯"""
        config = {"configurable": {"thread_id": conversation_id}}

        # è‡ªåŠ¨æ¢å¤æ¶ˆæ¯å†å²
        current_state = self.graph.get_state(config)
        print(f"æ¢å¤å¯¹è¯ï¼Œå·²æœ‰ {len(current_state.values['messages'])} æ¡æ¶ˆæ¯")

        # æ·»åŠ æ–°çš„ç”¨æˆ·è¾“å…¥
        result = await self.graph.ainvoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )

        return result

# æ¶ˆæ¯å†å²æŸ¥è¯¢å’Œç®¡ç†
class MessageHistoryManager:
    def __init__(self, checkpointer: SqliteSaver):
        self.checkpointer = checkpointer

    def get_conversation_history(self, conversation_id: str) -> list[BaseMessage]:
        """è·å–å®Œæ•´å¯¹è¯å†å²"""
        config = {"configurable": {"thread_id": conversation_id}}
        state = self.graph.get_state(config)
        return state.values.get("messages", [])

    def get_conversation_summary(self, conversation_id: str) -> dict:
        """è·å–å¯¹è¯æ‘˜è¦ä¿¡æ¯"""
        messages = self.get_conversation_history(conversation_id)

        return {
            "total_messages": len(messages),
            "message_types": self._count_message_types(messages),
            "conversation_length": self._calculate_total_tokens(messages),
            "time_span": self._get_time_span(messages)
        }

    def search_messages(self, conversation_id: str, query: str) -> list[BaseMessage]:
        """æœç´¢æ¶ˆæ¯å†å²"""
        messages = self.get_conversation_history(conversation_id)
        return [msg for msg in messages if query.lower() in msg.content.lower()]
```

#### é«˜çº§æ¶ˆæ¯ç®¡ç†ç‰¹æ€§
```python
# æ¶ˆæ¯è¿‡æ»¤å’Œä¼˜åŒ–
def message_filter_node(state: ConversationState) -> dict:
    """æ¶ˆæ¯è¿‡æ»¤èŠ‚ç‚¹ - ä¼˜åŒ–ä¸Šä¸‹æ–‡é•¿åº¦"""
    messages = state["messages"]

    # ç­–ç•¥1: ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
    recent_messages = messages[-20:] if len(messages) > 20 else messages

    # ç­–ç•¥2: æ™ºèƒ½æ‘˜è¦å‹ç¼©
    if len(messages) > 50:
        summary = create_conversation_summary(messages[:-10])
        compressed_messages = [
            SystemMessage(content=f"å¯¹è¯æ‘˜è¦: {summary}")
        ] + messages[-10:]  # ä¿ç•™æœ€è¿‘10æ¡å®Œæ•´æ¶ˆæ¯
        return {"messages": compressed_messages}

    return {"messages": recent_messages}

# åˆ†æ”¯å¯¹è¯ç®¡ç†
async def create_conversation_branch(
    original_conversation_id: str,
    branch_point: int,
    new_branch_id: str
):
    """ä»ç‰¹å®šç‚¹åˆ›å»ºå¯¹è¯åˆ†æ”¯"""

    # è·å–åŸå§‹å¯¹è¯çŠ¶æ€
    original_config = {"configurable": {"thread_id": original_conversation_id}}
    original_state = graph.get_state(original_config)

    # åˆ›å»ºåˆ†æ”¯çŠ¶æ€
    branch_messages = original_state.values["messages"][:branch_point]
    branch_state = ConversationState(
        messages=branch_messages,
        conversation_id=new_branch_id,
        user_id=original_state.values["user_id"]
    )

    # åˆå§‹åŒ–æ–°åˆ†æ”¯
    branch_config = {"configurable": {"thread_id": new_branch_id}}
    await graph.ainvoke(branch_state, config=branch_config)

    return new_branch_id
```

### 2. ADK - æ™ºèƒ½ä½“ç»§æ‰¿å¼æ¶ˆæ¯ç®¡ç†

ADKé€šè¿‡**InvocationContext**å’Œ**ä¼šè¯çŠ¶æ€**å®ç°å±‚æ¬¡åŒ–çš„æ¶ˆæ¯ç®¡ç†ã€‚

#### ä¼šè¯çŠ¶æ€ç®¡ç†
```python
from agent_dev_kit import InvocationContext, Event, EventActions
from agent_dev_kit.core import types

class ConversationSession:
    """ADKå¯¹è¯ä¼šè¯ç®¡ç†"""

    def __init__(self, session_id: str):
        self.session_id = session_id
        self.message_history: list[types.Content] = []
        self.context_cache: dict = {}
        self.agent_states: dict[str, Any] = {}

    def add_message(self, message: types.Content, author: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        timestamped_message = {
            "content": message,
            "author": author,
            "timestamp": datetime.now().isoformat(),
            "message_id": f"msg_{len(self.message_history)}"
        }
        self.message_history.append(timestamped_message)

    def get_recent_messages(self, limit: int = 10) -> list[types.Content]:
        """è·å–æœ€è¿‘çš„æ¶ˆæ¯"""
        return self.message_history[-limit:] if limit else self.message_history

    def get_messages_for_agent(self, agent_name: str) -> list[types.Content]:
        """è·å–ç‰¹å®šæ™ºèƒ½ä½“ç›¸å…³çš„æ¶ˆæ¯"""
        # è¿‡æ»¤å‡ºæ™ºèƒ½ä½“ç›¸å…³çš„æ¶ˆæ¯
        agent_messages = []
        for msg in self.message_history:
            if (msg["author"] == agent_name or
                agent_name in msg.get("mentioned_agents", [])):
                agent_messages.append(msg)
        return agent_messages

# æ™ºèƒ½ä½“æ¶ˆæ¯ç®¡ç†
class MessageAwareLlmAgent(LlmAgent):
    """æ¶ˆæ¯æ„ŸçŸ¥çš„LLMæ™ºèƒ½ä½“"""

    include_contents: Literal['default', 'none', 'recent', 'filtered'] = 'default'
    message_limit: int = 20

    async def _prepare_conversation_context(self, ctx: InvocationContext) -> list[types.Content]:
        """å‡†å¤‡å¯¹è¯ä¸Šä¸‹æ–‡"""

        # è·å–ä¼šè¯ç®¡ç†å™¨
        session = self._get_session(ctx)

        if self.include_contents == 'none':
            # ä¸åŒ…å«å†å²æ¶ˆæ¯
            return []
        elif self.include_contents == 'recent':
            # åªåŒ…å«æœ€è¿‘çš„æ¶ˆæ¯
            return session.get_recent_messages(self.message_limit)
        elif self.include_contents == 'filtered':
            # æ™ºèƒ½è¿‡æ»¤æ¶ˆæ¯
            return self._filter_relevant_messages(ctx, session)
        else:
            # é»˜è®¤ç­–ç•¥ï¼šåŒ…å«æ‰€æœ‰ç›¸å…³æ¶ˆæ¯
            return session.get_messages_for_agent(self.name)

    def _filter_relevant_messages(self, ctx: InvocationContext, session: ConversationSession) -> list[types.Content]:
        """æ™ºèƒ½è¿‡æ»¤ç›¸å…³æ¶ˆæ¯"""
        all_messages = session.message_history

        # è¿‡æ»¤ç­–ç•¥
        filtered_messages = []
        current_topic = self._extract_current_topic(ctx)

        for msg in all_messages:
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
            if msg.get("role") == "system":
                filtered_messages.append(msg)
                continue

            # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
            if len(all_messages) - all_messages.index(msg) <= 5:
                filtered_messages.append(msg)
                continue

            # ä¿ç•™ä¸»é¢˜ç›¸å…³çš„æ¶ˆæ¯
            if self._is_topic_relevant(msg["content"], current_topic):
                filtered_messages.append(msg)

        return filtered_messages

# å¤šæ™ºèƒ½ä½“æ¶ˆæ¯åè°ƒ
class MultiAgentMessageCoordinator:
    """å¤šæ™ºèƒ½ä½“æ¶ˆæ¯åè°ƒå™¨"""

    def __init__(self):
        self.agent_contexts: dict[str, list[types.Content]] = {}
        self.shared_context: list[types.Content] = []

    async def coordinate_message_flow(self, ctx: InvocationContext, event: Event):
        """åè°ƒæ™ºèƒ½ä½“é—´çš„æ¶ˆæ¯æµ"""

        current_agent = ctx.agent.name

        # è®°å½•æ™ºèƒ½ä½“è¾“å‡º
        if event.content:
            self._record_agent_message(current_agent, event.content)

        # æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡
        if self._should_share_message(event):
            self.shared_context.append({
                "content": event.content,
                "author": current_agent,
                "timestamp": datetime.now().isoformat(),
                "shared": True
            })

        # å‡†å¤‡ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡
        await self._prepare_next_agent_context(ctx, event)

    def _record_agent_message(self, agent_name: str, content: types.Content):
        """è®°å½•æ™ºèƒ½ä½“æ¶ˆæ¯"""
        if agent_name not in self.agent_contexts:
            self.agent_contexts[agent_name] = []

        self.agent_contexts[agent_name].append({
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "private": True
        })

    async def _prepare_next_agent_context(self, ctx: InvocationContext, current_event: Event):
        """ä¸ºä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“å‡†å¤‡ä¸Šä¸‹æ–‡"""

        # è¯†åˆ«ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
        next_agent = self._determine_next_agent(ctx, current_event)

        if next_agent:
            # ç»„åˆä¸Šä¸‹æ–‡ï¼šå…±äº«æ¶ˆæ¯ + ç‰¹å®šæ¶ˆæ¯
            context_messages = (
                self.shared_context +
                self.agent_contexts.get(next_agent.name, [])
            )

            # è®¾ç½®ä¸Šä¸‹æ–‡åˆ°ä¼šè¯çŠ¶æ€
            ctx.set_state_value(f"{next_agent.name}_context", context_messages)
```

#### é™æ€æŒ‡ä»¤ä¸ä¸Šä¸‹æ–‡ç¼“å­˜
```python
class CachedConversationAgent(LlmAgent):
    """æ”¯æŒä¸Šä¸‹æ–‡ç¼“å­˜çš„å¯¹è¯æ™ºèƒ½ä½“"""

    # é™æ€æŒ‡ä»¤ç”¨äºç¼“å­˜ä¼˜åŒ–
    static_instruction: Optional[types.Content] = types.Content(
        role='system',
        parts=[types.Part(text="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„æ€åº¦ã€‚")]
    )

    async def _build_llm_request(self, ctx: InvocationContext) -> types.LlmRequest:
        """æ„å»ºLLMè¯·æ±‚ï¼Œä¼˜åŒ–ç¼“å­˜ä½¿ç”¨"""

        # è·å–åŠ¨æ€æŒ‡ä»¤
        dynamic_instruction, _ = await self.canonical_instruction(ctx)

        # è·å–å†å²æ¶ˆæ¯
        conversation_history = await self._get_conversation_history(ctx)

        # æ„å»ºè¯·æ±‚å†…å®¹
        contents = []

        # 1. é™æ€æŒ‡ä»¤ï¼ˆå¯è¢«ç¼“å­˜ï¼‰
        if self.static_instruction:
            contents.append(self.static_instruction)

        # 2. å†å²æ¶ˆæ¯
        contents.extend(conversation_history)

        # 3. åŠ¨æ€æŒ‡ä»¤ï¼ˆä½œä¸ºç”¨æˆ·æ¶ˆæ¯ï¼‰
        if dynamic_instruction:
            contents.append(types.Content(
                role='user',
                parts=[types.Part(text=dynamic_instruction)]
            ))

        return types.LlmRequest(
            model=self.model,
            contents=contents,
            generation_config=self.generate_content_config
        )

    async def _get_conversation_history(self, ctx: InvocationContext) -> list[types.Content]:
        """è·å–ä¼˜åŒ–åçš„å¯¹è¯å†å²"""

        session = self._get_session(ctx)
        raw_history = session.get_recent_messages(self.message_limit)

        # è½¬æ¢ä¸ºLLMæ ¼å¼
        llm_messages = []
        for msg in raw_history:
            if isinstance(msg, dict):
                llm_messages.append(types.Content(
                    role=msg.get("role", "user"),
                    parts=[types.Part(text=str(msg["content"]))]
                ))
            else:
                llm_messages.append(msg)

        return llm_messages

# ä¼šè¯æŒä¹…åŒ–
class SessionPersistenceManager:
    """ä¼šè¯æŒä¹…åŒ–ç®¡ç†å™¨"""

    def __init__(self, storage_backend: str = "sqlite"):
        self.storage_backend = storage_backend
        self.db_connection = self._init_storage()

    async def save_session(self, session: ConversationSession):
        """ä¿å­˜ä¼šè¯çŠ¶æ€"""
        session_data = {
            "session_id": session.session_id,
            "message_history": session.message_history,
            "context_cache": session.context_cache,
            "agent_states": session.agent_states,
            "last_updated": datetime.now().isoformat()
        }

        # åºåˆ—åŒ–å¹¶ä¿å­˜
        serialized_data = json.dumps(session_data, default=str)
        await self._save_to_storage(session.session_id, serialized_data)

    async def load_session(self, session_id: str) -> Optional[ConversationSession]:
        """åŠ è½½ä¼šè¯çŠ¶æ€"""
        serialized_data = await self._load_from_storage(session_id)

        if not serialized_data:
            return None

        session_data = json.loads(serialized_data)

        # é‡å»ºä¼šè¯å¯¹è±¡
        session = ConversationSession(session_id)
        session.message_history = session_data["message_history"]
        session.context_cache = session_data["context_cache"]
        session.agent_states = session_data["agent_states"]

        return session
```

### 3. Vercel AI SDK - æµå¼æ¶ˆæ¯ç®¡ç†

Vercel AI SDKé€šè¿‡**æµå¼çŠ¶æ€**å’Œ**å®æ—¶æ›´æ–°**æœºåˆ¶ç®¡ç†æ¶ˆæ¯å†å²ã€‚

#### æµå¼æ¶ˆæ¯çŠ¶æ€ç®¡ç†
```typescript
interface ConversationState {
  messages: Array<{
    id: string;
    role: 'user' | 'assistant' | 'system';
    content: string;
    timestamp: Date;
    metadata?: any;
  }>;
  conversationId: string;
  isStreaming: boolean;
  currentMessage: string;
}

class StreamingConversationManager {
  private state: ConversationState;
  private stateUpdateCallbacks: Array<(state: ConversationState) => void> = [];

  constructor(conversationId: string) {
    this.state = {
      messages: [],
      conversationId,
      isStreaming: false,
      currentMessage: ''
    };
  }

  // æµå¼æ¶ˆæ¯å¤„ç†
  async processStreamingMessage(userInput: string): Promise<string> {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    this.addMessage({
      role: 'user',
      content: userInput,
      timestamp: new Date()
    });

    this.updateState({ isStreaming: true, currentMessage: '' });

    try {
      const result = await streamText({
        model: openai('gpt-4'),
        messages: this.formatMessagesForLLM(),

        // å®æ—¶å¤„ç†æµå¼å“åº”
        onChunk: ({ chunk }) => {
          switch (chunk.type) {
            case 'text-delta':
              this.appendToCurrentMessage(chunk.textDelta);
              break;

            case 'tool-call':
              this.handleToolCall(chunk);
              break;

            case 'tool-result':
              this.handleToolResult(chunk);
              break;
          }
        },

        onFinish: ({ text, toolCalls, usage }) => {
          // å®Œæˆæ—¶æ·»åŠ å®Œæ•´çš„AIå“åº”
          this.addMessage({
            role: 'assistant',
            content: text,
            timestamp: new Date(),
            metadata: { toolCalls, usage }
          });

          this.updateState({
            isStreaming: false,
            currentMessage: ''
          });
        }
      });

      return result.text;

    } catch (error) {
      this.updateState({ isStreaming: false });
      throw error;
    }
  }

  private addMessage(message: Omit<ConversationState['messages'][0], 'id'>) {
    const newMessage = {
      ...message,
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    };

    this.state.messages.push(newMessage);
    this.notifyStateUpdate();
  }

  private appendToCurrentMessage(delta: string) {
    this.state.currentMessage += delta;
    this.notifyStateUpdate();
  }

  private formatMessagesForLLM() {
    return this.state.messages.map(msg => ({
      role: msg.role,
      content: msg.content
    }));
  }

  // æ¶ˆæ¯å†å²ç®¡ç†
  getMessageHistory(limit?: number): ConversationState['messages'] {
    if (limit) {
      return this.state.messages.slice(-limit);
    }
    return [...this.state.messages];
  }

  searchMessages(query: string): ConversationState['messages'] {
    return this.state.messages.filter(msg =>
      msg.content.toLowerCase().includes(query.toLowerCase())
    );
  }

  deleteMessage(messageId: string): boolean {
    const index = this.state.messages.findIndex(msg => msg.id === messageId);
    if (index !== -1) {
      this.state.messages.splice(index, 1);
      this.notifyStateUpdate();
      return true;
    }
    return false;
  }

  editMessage(messageId: string, newContent: string): boolean {
    const message = this.state.messages.find(msg => msg.id === messageId);
    if (message) {
      message.content = newContent;
      message.metadata = { ...message.metadata, edited: true };
      this.notifyStateUpdate();
      return true;
    }
    return false;
  }
}
```

#### Reacté›†æˆå’ŒçŠ¶æ€ç®¡ç†
```typescript
// React Hook for conversation management
function useConversation(conversationId: string) {
  const [state, setState] = useState<ConversationState>({
    messages: [],
    conversationId,
    isStreaming: false,
    currentMessage: ''
  });

  const [manager] = useState(() => new StreamingConversationManager(conversationId));

  useEffect(() => {
    // è®¢é˜…çŠ¶æ€æ›´æ–°
    const unsubscribe = manager.onStateUpdate((newState) => {
      setState(newState);
    });

    // åŠ è½½å†å²æ¶ˆæ¯
    loadConversationHistory(conversationId).then(history => {
      if (history) {
        setState(prev => ({ ...prev, messages: history }));
      }
    });

    return unsubscribe;
  }, [conversationId, manager]);

  const sendMessage = useCallback(async (content: string) => {
    try {
      await manager.processStreamingMessage(content);
      // ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
      await saveConversationHistory(conversationId, state.messages);
    } catch (error) {
      console.error('Failed to send message:', error);
    }
  }, [manager, conversationId, state.messages]);

  return {
    messages: state.messages,
    currentMessage: state.currentMessage,
    isStreaming: state.isStreaming,
    sendMessage,
    searchMessages: manager.searchMessages.bind(manager),
    deleteMessage: manager.deleteMessage.bind(manager),
    editMessage: manager.editMessage.bind(manager)
  };
}

// é«˜çº§æ¶ˆæ¯ç®¡ç†åŠŸèƒ½
class AdvancedMessageManager {
  private conversationStore: Map<string, ConversationState> = new Map();

  // æ¶ˆæ¯å‹ç¼©å’Œä¼˜åŒ–
  compressConversation(conversationId: string, maxMessages: number = 20): boolean {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return false;

    if (conversation.messages.length <= maxMessages) return false;

    // ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„æ¶ˆæ¯
    const systemMessages = conversation.messages.filter(msg => msg.role === 'system');
    const recentMessages = conversation.messages.slice(-maxMessages + systemMessages.length);

    // åˆ›å»ºæ‘˜è¦
    const oldMessages = conversation.messages.slice(0, -maxMessages + systemMessages.length);
    const summary = this.createConversationSummary(oldMessages);

    // é‡å»ºæ¶ˆæ¯åˆ—è¡¨
    conversation.messages = [
      ...systemMessages,
      {
        id: `summary_${Date.now()}`,
        role: 'system' as const,
        content: `å¯¹è¯å†å²æ‘˜è¦: ${summary}`,
        timestamp: new Date()
      },
      ...recentMessages.filter(msg => msg.role !== 'system')
    ];

    return true;
  }

  private createConversationSummary(messages: ConversationState['messages']): string {
    // ç®€åŒ–çš„æ‘˜è¦ç”Ÿæˆé€»è¾‘
    const userMessages = messages.filter(msg => msg.role === 'user');
    const topics = userMessages.map(msg => this.extractTopic(msg.content));

    return `ç”¨æˆ·ä¸»è¦è®¨è®ºäº†ä»¥ä¸‹è¯é¢˜: ${topics.join(', ')}`;
  }

  // æ¶ˆæ¯åˆ†æ”¯ç®¡ç†
  createMessageBranch(
    conversationId: string,
    fromMessageId: string,
    newBranchId: string
  ): boolean {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return false;

    const messageIndex = conversation.messages.findIndex(msg => msg.id === fromMessageId);
    if (messageIndex === -1) return false;

    // åˆ›å»ºåˆ†æ”¯å¯¹è¯
    const branchMessages = conversation.messages.slice(0, messageIndex + 1);
    const branchConversation: ConversationState = {
      messages: [...branchMessages],
      conversationId: newBranchId,
      isStreaming: false,
      currentMessage: ''
    };

    this.conversationStore.set(newBranchId, branchConversation);
    return true;
  }

  // æ¶ˆæ¯å¯¼å‡ºå’Œå¯¼å…¥
  exportConversation(conversationId: string): string | null {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return null;

    return JSON.stringify({
      ...conversation,
      exportedAt: new Date().toISOString(),
      version: '1.0'
    });
  }

  importConversation(conversationData: string): string | null {
    try {
      const parsed = JSON.parse(conversationData);
      const conversationId = parsed.conversationId || `imported_${Date.now()}`;

      this.conversationStore.set(conversationId, {
        messages: parsed.messages || [],
        conversationId,
        isStreaming: false,
        currentMessage: ''
      });

      return conversationId;
    } catch (error) {
      console.error('Failed to import conversation:', error);
      return null;
    }
  }
}
```

#### æŒä¹…åŒ–å­˜å‚¨æ–¹æ¡ˆ
```typescript
// æµè§ˆå™¨å­˜å‚¨é€‚é…å™¨
class BrowserStorageAdapter {
  private storageKey = 'conversation_history';

  async saveConversation(conversationId: string, messages: any[]): Promise<void> {
    try {
      const stored = localStorage.getItem(this.storageKey);
      const conversations = stored ? JSON.parse(stored) : {};

      conversations[conversationId] = {
        messages,
        lastUpdated: new Date().toISOString()
      };

      localStorage.setItem(this.storageKey, JSON.stringify(conversations));
    } catch (error) {
      console.error('Failed to save conversation:', error);
    }
  }

  async loadConversation(conversationId: string): Promise<any[] | null> {
    try {
      const stored = localStorage.getItem(this.storageKey);
      if (!stored) return null;

      const conversations = JSON.parse(stored);
      return conversations[conversationId]?.messages || null;
    } catch (error) {
      console.error('Failed to load conversation:', error);
      return null;
    }
  }
}

// æœåŠ¡ç«¯å­˜å‚¨é€‚é…å™¨
class ServerStorageAdapter {
  constructor(private apiBase: string) {}

  async saveConversation(conversationId: string, messages: any[]): Promise<void> {
    await fetch(`${this.apiBase}/conversations/${conversationId}`, {
      method: 'PUT',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ messages })
    });
  }

  async loadConversation(conversationId: string): Promise<any[] | null> {
    const response = await fetch(`${this.apiBase}/conversations/${conversationId}`);
    if (response.ok) {
      const data = await response.json();
      return data.messages;
    }
    return null;
  }
}
```

### 4. AG-UI - ç»„ä»¶åŒ–æ¶ˆæ¯ç®¡ç†

AG-UIé€šè¿‡Reactç»„ä»¶çŠ¶æ€å’Œè‡ªå®šä¹‰Hookå®ç°å‰ç«¯æ¶ˆæ¯ç®¡ç†ã€‚

#### Reactç»„ä»¶çŠ¶æ€ç®¡ç†
```typescript
interface MessageState {
  id: string;
  content: string;
  role: 'user' | 'assistant' | 'system';
  timestamp: Date;
  status: 'sending' | 'sent' | 'error';
  metadata?: {
    agentName?: string;
    toolCalls?: any[];
    reasoning?: string;
  };
}

interface ConversationComponentState {
  messages: MessageState[];
  isLoading: boolean;
  error: string | null;
  agentState: any;
  currentNode: string;
}

function ConversationManager() {
  const [state, setState] = useState<ConversationComponentState>({
    messages: [],
    isLoading: false,
    error: null,
    agentState: null,
    currentNode: ''
  });

  // ä½¿ç”¨AG-UIçš„useCoAgent Hook
  const {
    state: agentState,
    nodeName,
    invoke
  } = useCoAgent<TravelAgentState>({
    name: "conversation_agent",
    initialState: INITIAL_STATE,

    // å®æ—¶ç›‘å¬æ™ºèƒ½ä½“çŠ¶æ€å˜åŒ–
    onChunk: (chunk) => {
      handleAgentChunk(chunk);
    },

    config: {
      streamSubgraphs: true,
      enableRealTimeUpdates: true
    }
  });

  const handleAgentChunk = useCallback((chunk: any) => {
    switch (chunk.type) {
      case 'agent-message':
        addMessage({
          content: chunk.content,
          role: 'assistant',
          metadata: {
            agentName: chunk.agentName,
            reasoning: chunk.reasoning
          }
        });
        break;

      case 'tool-call':
        addMessage({
          content: `æ­£åœ¨è°ƒç”¨å·¥å…·: ${chunk.toolName}`,
          role: 'system',
          metadata: { toolCalls: [chunk] }
        });
        break;

      case 'error':
        setState(prev => ({
          ...prev,
          error: chunk.error,
          isLoading: false
        }));
        break;
    }
  }, []);

  const addMessage = useCallback((message: Omit<MessageState, 'id' | 'timestamp' | 'status'>) => {
    const newMessage: MessageState = {
      ...message,
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      timestamp: new Date(),
      status: 'sent'
    };

    setState(prev => ({
      ...prev,
      messages: [...prev.messages, newMessage]
    }));
  }, []);

  const sendMessage = useCallback(async (content: string) => {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    addMessage({ content, role: 'user' });

    setState(prev => ({ ...prev, isLoading: true, error: null }));

    try {
      await invoke({ userInput: content });
    } catch (error) {
      setState(prev => ({
        ...prev,
        error: error.message,
        isLoading: false
      }));
    }
  }, [invoke, addMessage]);

  return {
    messages: state.messages,
    isLoading: state.isLoading,
    error: state.error,
    agentState,
    currentNode: nodeName,
    sendMessage,
    addMessage
  };
}
```

#### æ¶ˆæ¯ç»„ä»¶å’Œè™šæ‹ŸåŒ–
```typescript
// é«˜æ€§èƒ½æ¶ˆæ¯åˆ—è¡¨ç»„ä»¶
const MessageList = React.memo(({
  messages,
  isLoading
}: {
  messages: MessageState[];
  isLoading: boolean;
}) => {
  const listRef = useRef<HTMLDivElement>(null);

  // è™šæ‹ŸåŒ–æ¸²æŸ“ä¼˜åŒ–
  const visibleMessages = useMemo(() => {
    // åªæ¸²æŸ“å¯è§çš„æ¶ˆæ¯
    return messages.slice(-50); // æœ€è¿‘50æ¡æ¶ˆæ¯
  }, [messages]);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    if (listRef.current) {
      listRef.current.scrollTop = listRef.current.scrollHeight;
    }
  }, [messages]);

  return (
    <div ref={listRef} className="message-list">
      {visibleMessages.map((message) => (
        <MessageComponent
          key={message.id}
          message={message}
        />
      ))}

      {isLoading && (
        <div className="loading-indicator">
          <TypingIndicator />
        </div>
      )}
    </div>
  );
});

// å•ä¸ªæ¶ˆæ¯ç»„ä»¶
const MessageComponent = React.memo(({ message }: { message: MessageState }) => {
  const [isExpanded, setIsExpanded] = useState(false);

  return (
    <div className={`message ${message.role}`}>
      <div className="message-header">
        <span className="role">{message.role}</span>
        {message.metadata?.agentName && (
          <span className="agent-name">{message.metadata.agentName}</span>
        )}
        <span className="timestamp">
          {message.timestamp.toLocaleTimeString()}
        </span>
      </div>

      <div className="message-content">
        {message.content}
      </div>

      {message.metadata?.reasoning && (
        <div className="message-metadata">
          <button
            onClick={() => setIsExpanded(!isExpanded)}
            className="expand-button"
          >
            {isExpanded ? 'éšè—' : 'æ˜¾ç¤º'}æ¨ç†è¿‡ç¨‹
          </button>

          {isExpanded && (
            <div className="reasoning">
              {message.metadata.reasoning}
            </div>
          )}
        </div>
      )}

      {message.metadata?.toolCalls && (
        <div className="tool-calls">
          {message.metadata.toolCalls.map((call, index) => (
            <ToolCallComponent key={index} toolCall={call} />
          ))}
        </div>
      )}
    </div>
  );
});
```

#### æœ¬åœ°å­˜å‚¨å’ŒåŒæ­¥
```typescript
// æµè§ˆå™¨å­˜å‚¨Hook
function useConversationPersistence(conversationId: string) {
  const storageKey = `conversation_${conversationId}`;

  const saveToStorage = useCallback((messages: MessageState[]) => {
    try {
      const data = {
        messages,
        lastUpdated: new Date().toISOString(),
        version: '1.0'
      };
      localStorage.setItem(storageKey, JSON.stringify(data));
    } catch (error) {
      console.error('Failed to save conversation:', error);
    }
  }, [storageKey]);

  const loadFromStorage = useCallback((): MessageState[] | null => {
    try {
      const stored = localStorage.getItem(storageKey);
      if (!stored) return null;

      const data = JSON.parse(stored);
      return data.messages || null;
    } catch (error) {
      console.error('Failed to load conversation:', error);
      return null;
    }
  }, [storageKey]);

  const clearStorage = useCallback(() => {
    localStorage.removeItem(storageKey);
  }, [storageKey]);

  return { saveToStorage, loadFromStorage, clearStorage };
}

// è‡ªåŠ¨ä¿å­˜Hook
function useAutoSave(
  messages: MessageState[],
  conversationId: string,
  debounceMs: number = 1000
) {
  const { saveToStorage } = useConversationPersistence(conversationId);

  const debouncedSave = useMemo(
    () => debounce(saveToStorage, debounceMs),
    [saveToStorage, debounceMs]
  );

  useEffect(() => {
    if (messages.length > 0) {
      debouncedSave(messages);
    }
  }, [messages, debouncedSave]);

  // æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      debouncedSave.cancel();
    };
  }, [debouncedSave]);
}
```

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”

### 1. å†…å­˜ç®¡ç†
- **LangGraph**: è‡ªåŠ¨çŠ¶æ€å‹ç¼© + æ£€æŸ¥ç‚¹å¸è½½
- **ADK**: é™æ€æŒ‡ä»¤ç¼“å­˜ + ä¼šè¯åˆ†ç‰‡
- **Vercel AI SDK**: æµå¼ä¼ è¾“ + å®¢æˆ·ç«¯ç¼“å­˜
- **AG-UI**: è™šæ‹ŸåŒ–æ¸²æŸ“ + æ‡’åŠ è½½

### 2. å­˜å‚¨ä¼˜åŒ–
- **LangGraph**: SQLite/PostgreSQLæ£€æŸ¥ç‚¹
- **ADK**: åºåˆ—åŒ–çŠ¶æ€ + å¢é‡æ›´æ–°
- **Vercel AI SDK**: è‡ªå®šä¹‰å­˜å‚¨é€‚é…å™¨
- **AG-UI**: æµè§ˆå™¨å­˜å‚¨ + å‹ç¼©

### 3. ç½‘ç»œä¼˜åŒ–
- **LangGraph**: çŠ¶æ€å·®åˆ†ä¼ è¾“
- **ADK**: äº‹ä»¶é©±åŠ¨æ›´æ–°
- **Vercel AI SDK**: æµå¼ä¼ è¾“ + æ–­ç‚¹ç»­ä¼ 
- **AG-UI**: WebSocketå®æ—¶åŒæ­¥

## æœ€ä½³å®è·µå»ºè®®

### 1. é€‰æ‹©åˆé€‚çš„å­˜å‚¨ç­–ç•¥
```python
# æ ¹æ®åœºæ™¯é€‰æ‹©å­˜å‚¨æ–¹æ¡ˆ
if conversation_length > 1000:
    # é•¿å¯¹è¯ï¼šä½¿ç”¨å‹ç¼©å’Œæ‘˜è¦
    use_conversation_compression()
elif real_time_requirements:
    # å®æ—¶åœºæ™¯ï¼šä½¿ç”¨æµå¼çŠ¶æ€
    use_streaming_state()
elif enterprise_compliance:
    # ä¼ä¸šåœºæ™¯ï¼šä½¿ç”¨åŠ å¯†å­˜å‚¨
    use_encrypted_persistence()
```

### 2. å®ç°æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
```python
def optimize_context_window(messages, max_tokens=4000):
    """æ™ºèƒ½ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£"""

    # ç­–ç•¥1: ä¿ç•™å…³é”®æ¶ˆæ¯
    key_messages = extract_key_messages(messages)

    # ç­–ç•¥2: åˆ›å»ºå¯¹è¯æ‘˜è¦
    if calculate_tokens(messages) > max_tokens:
        summary = create_summary(messages[:-10])
        return [summary] + messages[-10:]

    return messages
```

### 3. å®ç°å¤šçº§ç¼“å­˜ç­–ç•¥
```typescript
// å¤šçº§ç¼“å­˜å®ç°
class MessageCacheManager {
  private memoryCache = new Map();
  private diskCache = new LocalStorageCache();
  private serverCache = new ServerCache();

  async getMessage(id: string) {
    // L1: å†…å­˜ç¼“å­˜
    if (this.memoryCache.has(id)) {
      return this.memoryCache.get(id);
    }

    // L2: æœ¬åœ°å­˜å‚¨
    const diskResult = await this.diskCache.get(id);
    if (diskResult) {
      this.memoryCache.set(id, diskResult);
      return diskResult;
    }

    // L3: æœåŠ¡å™¨ç¼“å­˜
    const serverResult = await this.serverCache.get(id);
    if (serverResult) {
      this.diskCache.set(id, serverResult);
      this.memoryCache.set(id, serverResult);
      return serverResult;
    }

    return null;
  }
}
```

## æ€»ç»“

å„æ¡†æ¶çš„æ¶ˆæ¯å†å²ç®¡ç†èƒ½åŠ›æ’åºï¼š

1. **LangGraph** - æœ€å®Œå–„çš„è‡ªåŠ¨åŒ–æ¶ˆæ¯ç®¡ç†ï¼Œæ£€æŸ¥ç‚¹æœºåˆ¶å¼ºå¤§
2. **ADK** - ä¼ä¸šçº§ä¼šè¯ç®¡ç†ï¼Œæ™ºèƒ½ä½“ç»§æ‰¿æœºåˆ¶ä¼˜ç§€
3. **Vercel AI SDK** - æµå¼å¤„ç†ä¼˜ç§€ï¼Œé€‚åˆå®æ—¶åº”ç”¨
4. **AG-UI** - å‰ç«¯ä½“éªŒæœ€ä½³ï¼Œç»„ä»¶åŒ–ç¨‹åº¦é«˜

**é€‰æ‹©å»ºè®®**ï¼š
- **å¤æ‚å¯¹è¯ç³»ç»Ÿ**: é€‰æ‹©LangGraphçš„è‡ªåŠ¨åŒ–ç®¡ç†
- **ä¼ä¸šçº§åº”ç”¨**: é€‰æ‹©ADKçš„ä¼šè¯çŠ¶æ€æœºåˆ¶
- **å®æ—¶äº¤äº’åº”ç”¨**: é€‰æ‹©Vercel AI SDKçš„æµå¼å¤„ç†
- **ç”¨æˆ·ç•Œé¢é‡ç‚¹**: é€‰æ‹©AG-UIçš„ç»„ä»¶åŒ–æ–¹æ¡ˆ

å…³é”®æˆåŠŸå› ç´ ï¼š
- ğŸ¯ **åˆé€‚çš„å­˜å‚¨ç­–ç•¥** - æ ¹æ®æ•°æ®é‡å’Œè®¿é—®æ¨¡å¼é€‰æ‹©
- âš¡ **æ€§èƒ½ä¼˜åŒ–** - å®ç°å¤šçº§ç¼“å­˜å’Œæ™ºèƒ½å‹ç¼©
- ğŸ”„ **çŠ¶æ€ä¸€è‡´æ€§** - ç¡®ä¿å¤šæ™ºèƒ½ä½“é—´çŠ¶æ€åŒæ­¥
- ğŸ“Š **ç›‘æ§å’Œè°ƒè¯•** - æä¾›å®Œæ•´çš„æ¶ˆæ¯è¿½è¸ªèƒ½åŠ›
