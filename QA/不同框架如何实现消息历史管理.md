# 不同框架如何实现消息历史管理？

## 问题分析

**消息历史管理**是多智能体系统的核心功能之一，它决定了智能体如何维护对话上下文、实现连续交互、优化性能，以及支持复杂的多轮对话场景。不同框架采用了各自独特的设计理念和技术实现。

## 各框架消息历史管理对比

| 框架 | 存储机制 | 持久化方案 | 上下文管理 | 性能优化 | 复杂度 |
|------|----------|-----------|-----------|----------|--------|
| **LangGraph** | MessagesState + 检查点 | SQLite/PostgreSQL | 自动累积 + 检查点 | 状态压缩 + 分支 | 低 |
| **ADK** | InvocationContext + 会话 | 会话状态 + 事件流 | 智能体继承 | 静态指令缓存 | 中 |
| **Vercel AI SDK** | 流式状态 + 内存 | 自定义存储 | 手动管理 | 流式传输 | 中 |
| **AG-UI** | React状态 + Hook | 浏览器存储 | 组件状态 | 虚拟化渲染 | 低 |

## 详细技术分析

### 1. LangGraph - 自动化消息状态管理

LangGraph通过**MessagesState**和**add_messages**机制实现了最先进的消息历史管理。

#### 核心消息状态定义
```python
from typing import Annotated
from langgraph.graph import MessagesState, add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

class ConversationState(MessagesState):
    """扩展的对话状态"""
    # 自动消息管理
    messages: Annotated[list[BaseMessage], add_messages]

    # 额外的上下文信息
    conversation_id: str
    user_id: str
    session_metadata: dict

    # 消息统计和管理
    total_tokens: int = 0
    last_activity: datetime = None
    conversation_summary: str = ""
```

#### 自动消息累积机制
```python
def chat_node(state: ConversationState) -> dict:
    """聊天节点 - 自动处理消息历史"""

    # LangGraph自动管理消息历史
    # state["messages"] 包含完整的对话历史
    messages = state["messages"]

    # 系统自动处理消息格式化和累积
    response = llm.invoke(messages)

    # 返回新消息，LangGraph自动添加到历史中
    return {
        "messages": [response],  # 自动append到现有messages
        "total_tokens": state["total_tokens"] + count_tokens(response),
        "last_activity": datetime.now()
    }

def user_input_node(state: ConversationState) -> dict:
    """用户输入节点"""
    user_message = HumanMessage(content=get_user_input())

    # 自动添加到消息历史
    return {"messages": [user_message]}
```

#### 检查点持久化机制
```python
from langgraph.checkpoint.sqlite import SqliteSaver

class ConversationManager:
    def __init__(self, db_path: str):
        self.checkpointer = SqliteSaver(db_path)
        self.graph = self._build_conversation_graph()

    def _build_conversation_graph(self):
        """构建对话图"""
        workflow = StateGraph(ConversationState)

        workflow.add_node("user_input", user_input_node)
        workflow.add_node("assistant", chat_node)
        workflow.add_node("summarizer", summary_node)

        # 编译时启用检查点
        return workflow.compile(checkpointer=self.checkpointer)

    async def continue_conversation(self, user_input: str, conversation_id: str):
        """继续现有对话"""
        config = {"configurable": {"thread_id": conversation_id}}

        # 自动恢复消息历史
        current_state = self.graph.get_state(config)
        print(f"恢复对话，已有 {len(current_state.values['messages'])} 条消息")

        # 添加新的用户输入
        result = await self.graph.ainvoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )

        return result

# 消息历史查询和管理
class MessageHistoryManager:
    def __init__(self, checkpointer: SqliteSaver):
        self.checkpointer = checkpointer

    def get_conversation_history(self, conversation_id: str) -> list[BaseMessage]:
        """获取完整对话历史"""
        config = {"configurable": {"thread_id": conversation_id}}
        state = self.graph.get_state(config)
        return state.values.get("messages", [])

    def get_conversation_summary(self, conversation_id: str) -> dict:
        """获取对话摘要信息"""
        messages = self.get_conversation_history(conversation_id)

        return {
            "total_messages": len(messages),
            "message_types": self._count_message_types(messages),
            "conversation_length": self._calculate_total_tokens(messages),
            "time_span": self._get_time_span(messages)
        }

    def search_messages(self, conversation_id: str, query: str) -> list[BaseMessage]:
        """搜索消息历史"""
        messages = self.get_conversation_history(conversation_id)
        return [msg for msg in messages if query.lower() in msg.content.lower()]
```

#### 高级消息管理特性
```python
# 消息过滤和优化
def message_filter_node(state: ConversationState) -> dict:
    """消息过滤节点 - 优化上下文长度"""
    messages = state["messages"]

    # 策略1: 保留最近N条消息
    recent_messages = messages[-20:] if len(messages) > 20 else messages

    # 策略2: 智能摘要压缩
    if len(messages) > 50:
        summary = create_conversation_summary(messages[:-10])
        compressed_messages = [
            SystemMessage(content=f"对话摘要: {summary}")
        ] + messages[-10:]  # 保留最近10条完整消息
        return {"messages": compressed_messages}

    return {"messages": recent_messages}

# 分支对话管理
async def create_conversation_branch(
    original_conversation_id: str,
    branch_point: int,
    new_branch_id: str
):
    """从特定点创建对话分支"""

    # 获取原始对话状态
    original_config = {"configurable": {"thread_id": original_conversation_id}}
    original_state = graph.get_state(original_config)

    # 创建分支状态
    branch_messages = original_state.values["messages"][:branch_point]
    branch_state = ConversationState(
        messages=branch_messages,
        conversation_id=new_branch_id,
        user_id=original_state.values["user_id"]
    )

    # 初始化新分支
    branch_config = {"configurable": {"thread_id": new_branch_id}}
    await graph.ainvoke(branch_state, config=branch_config)

    return new_branch_id
```

### 2. ADK - 智能体继承式消息管理

ADK通过**InvocationContext**和**会话状态**实现层次化的消息管理。

#### 会话状态管理
```python
from agent_dev_kit import InvocationContext, Event, EventActions
from agent_dev_kit.core import types

class ConversationSession:
    """ADK对话会话管理"""

    def __init__(self, session_id: str):
        self.session_id = session_id
        self.message_history: list[types.Content] = []
        self.context_cache: dict = {}
        self.agent_states: dict[str, Any] = {}

    def add_message(self, message: types.Content, author: str):
        """添加消息到历史"""
        timestamped_message = {
            "content": message,
            "author": author,
            "timestamp": datetime.now().isoformat(),
            "message_id": f"msg_{len(self.message_history)}"
        }
        self.message_history.append(timestamped_message)

    def get_recent_messages(self, limit: int = 10) -> list[types.Content]:
        """获取最近的消息"""
        return self.message_history[-limit:] if limit else self.message_history

    def get_messages_for_agent(self, agent_name: str) -> list[types.Content]:
        """获取特定智能体相关的消息"""
        # 过滤出智能体相关的消息
        agent_messages = []
        for msg in self.message_history:
            if (msg["author"] == agent_name or
                agent_name in msg.get("mentioned_agents", [])):
                agent_messages.append(msg)
        return agent_messages

# 智能体消息管理
class MessageAwareLlmAgent(LlmAgent):
    """消息感知的LLM智能体"""

    include_contents: Literal['default', 'none', 'recent', 'filtered'] = 'default'
    message_limit: int = 20

    async def _prepare_conversation_context(self, ctx: InvocationContext) -> list[types.Content]:
        """准备对话上下文"""

        # 获取会话管理器
        session = self._get_session(ctx)

        if self.include_contents == 'none':
            # 不包含历史消息
            return []
        elif self.include_contents == 'recent':
            # 只包含最近的消息
            return session.get_recent_messages(self.message_limit)
        elif self.include_contents == 'filtered':
            # 智能过滤消息
            return self._filter_relevant_messages(ctx, session)
        else:
            # 默认策略：包含所有相关消息
            return session.get_messages_for_agent(self.name)

    def _filter_relevant_messages(self, ctx: InvocationContext, session: ConversationSession) -> list[types.Content]:
        """智能过滤相关消息"""
        all_messages = session.message_history

        # 过滤策略
        filtered_messages = []
        current_topic = self._extract_current_topic(ctx)

        for msg in all_messages:
            # 保留系统消息
            if msg.get("role") == "system":
                filtered_messages.append(msg)
                continue

            # 保留最近的消息
            if len(all_messages) - all_messages.index(msg) <= 5:
                filtered_messages.append(msg)
                continue

            # 保留主题相关的消息
            if self._is_topic_relevant(msg["content"], current_topic):
                filtered_messages.append(msg)

        return filtered_messages

# 多智能体消息协调
class MultiAgentMessageCoordinator:
    """多智能体消息协调器"""

    def __init__(self):
        self.agent_contexts: dict[str, list[types.Content]] = {}
        self.shared_context: list[types.Content] = []

    async def coordinate_message_flow(self, ctx: InvocationContext, event: Event):
        """协调智能体间的消息流"""

        current_agent = ctx.agent.name

        # 记录智能体输出
        if event.content:
            self._record_agent_message(current_agent, event.content)

        # 更新共享上下文
        if self._should_share_message(event):
            self.shared_context.append({
                "content": event.content,
                "author": current_agent,
                "timestamp": datetime.now().isoformat(),
                "shared": True
            })

        # 准备下一个智能体的上下文
        await self._prepare_next_agent_context(ctx, event)

    def _record_agent_message(self, agent_name: str, content: types.Content):
        """记录智能体消息"""
        if agent_name not in self.agent_contexts:
            self.agent_contexts[agent_name] = []

        self.agent_contexts[agent_name].append({
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "private": True
        })

    async def _prepare_next_agent_context(self, ctx: InvocationContext, current_event: Event):
        """为下一个智能体准备上下文"""

        # 识别下一个智能体
        next_agent = self._determine_next_agent(ctx, current_event)

        if next_agent:
            # 组合上下文：共享消息 + 特定消息
            context_messages = (
                self.shared_context +
                self.agent_contexts.get(next_agent.name, [])
            )

            # 设置上下文到会话状态
            ctx.set_state_value(f"{next_agent.name}_context", context_messages)
```

#### 静态指令与上下文缓存
```python
class CachedConversationAgent(LlmAgent):
    """支持上下文缓存的对话智能体"""

    # 静态指令用于缓存优化
    static_instruction: Optional[types.Content] = types.Content(
        role='system',
        parts=[types.Part(text="你是一个专业的AI助手，请保持友好和专业的态度。")]
    )

    async def _build_llm_request(self, ctx: InvocationContext) -> types.LlmRequest:
        """构建LLM请求，优化缓存使用"""

        # 获取动态指令
        dynamic_instruction, _ = await self.canonical_instruction(ctx)

        # 获取历史消息
        conversation_history = await self._get_conversation_history(ctx)

        # 构建请求内容
        contents = []

        # 1. 静态指令（可被缓存）
        if self.static_instruction:
            contents.append(self.static_instruction)

        # 2. 历史消息
        contents.extend(conversation_history)

        # 3. 动态指令（作为用户消息）
        if dynamic_instruction:
            contents.append(types.Content(
                role='user',
                parts=[types.Part(text=dynamic_instruction)]
            ))

        return types.LlmRequest(
            model=self.model,
            contents=contents,
            generation_config=self.generate_content_config
        )

    async def _get_conversation_history(self, ctx: InvocationContext) -> list[types.Content]:
        """获取优化后的对话历史"""

        session = self._get_session(ctx)
        raw_history = session.get_recent_messages(self.message_limit)

        # 转换为LLM格式
        llm_messages = []
        for msg in raw_history:
            if isinstance(msg, dict):
                llm_messages.append(types.Content(
                    role=msg.get("role", "user"),
                    parts=[types.Part(text=str(msg["content"]))]
                ))
            else:
                llm_messages.append(msg)

        return llm_messages

# 会话持久化
class SessionPersistenceManager:
    """会话持久化管理器"""

    def __init__(self, storage_backend: str = "sqlite"):
        self.storage_backend = storage_backend
        self.db_connection = self._init_storage()

    async def save_session(self, session: ConversationSession):
        """保存会话状态"""
        session_data = {
            "session_id": session.session_id,
            "message_history": session.message_history,
            "context_cache": session.context_cache,
            "agent_states": session.agent_states,
            "last_updated": datetime.now().isoformat()
        }

        # 序列化并保存
        serialized_data = json.dumps(session_data, default=str)
        await self._save_to_storage(session.session_id, serialized_data)

    async def load_session(self, session_id: str) -> Optional[ConversationSession]:
        """加载会话状态"""
        serialized_data = await self._load_from_storage(session_id)

        if not serialized_data:
            return None

        session_data = json.loads(serialized_data)

        # 重建会话对象
        session = ConversationSession(session_id)
        session.message_history = session_data["message_history"]
        session.context_cache = session_data["context_cache"]
        session.agent_states = session_data["agent_states"]

        return session
```

### 3. Vercel AI SDK - 流式消息管理

Vercel AI SDK通过**流式状态**和**实时更新**机制管理消息历史。

#### 流式消息状态管理
```typescript
interface ConversationState {
  messages: Array<{
    id: string;
    role: 'user' | 'assistant' | 'system';
    content: string;
    timestamp: Date;
    metadata?: any;
  }>;
  conversationId: string;
  isStreaming: boolean;
  currentMessage: string;
}

class StreamingConversationManager {
  private state: ConversationState;
  private stateUpdateCallbacks: Array<(state: ConversationState) => void> = [];

  constructor(conversationId: string) {
    this.state = {
      messages: [],
      conversationId,
      isStreaming: false,
      currentMessage: ''
    };
  }

  // 流式消息处理
  async processStreamingMessage(userInput: string): Promise<string> {
    // 添加用户消息
    this.addMessage({
      role: 'user',
      content: userInput,
      timestamp: new Date()
    });

    this.updateState({ isStreaming: true, currentMessage: '' });

    try {
      const result = await streamText({
        model: openai('gpt-4'),
        messages: this.formatMessagesForLLM(),

        // 实时处理流式响应
        onChunk: ({ chunk }) => {
          switch (chunk.type) {
            case 'text-delta':
              this.appendToCurrentMessage(chunk.textDelta);
              break;

            case 'tool-call':
              this.handleToolCall(chunk);
              break;

            case 'tool-result':
              this.handleToolResult(chunk);
              break;
          }
        },

        onFinish: ({ text, toolCalls, usage }) => {
          // 完成时添加完整的AI响应
          this.addMessage({
            role: 'assistant',
            content: text,
            timestamp: new Date(),
            metadata: { toolCalls, usage }
          });

          this.updateState({
            isStreaming: false,
            currentMessage: ''
          });
        }
      });

      return result.text;

    } catch (error) {
      this.updateState({ isStreaming: false });
      throw error;
    }
  }

  private addMessage(message: Omit<ConversationState['messages'][0], 'id'>) {
    const newMessage = {
      ...message,
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    };

    this.state.messages.push(newMessage);
    this.notifyStateUpdate();
  }

  private appendToCurrentMessage(delta: string) {
    this.state.currentMessage += delta;
    this.notifyStateUpdate();
  }

  private formatMessagesForLLM() {
    return this.state.messages.map(msg => ({
      role: msg.role,
      content: msg.content
    }));
  }

  // 消息历史管理
  getMessageHistory(limit?: number): ConversationState['messages'] {
    if (limit) {
      return this.state.messages.slice(-limit);
    }
    return [...this.state.messages];
  }

  searchMessages(query: string): ConversationState['messages'] {
    return this.state.messages.filter(msg =>
      msg.content.toLowerCase().includes(query.toLowerCase())
    );
  }

  deleteMessage(messageId: string): boolean {
    const index = this.state.messages.findIndex(msg => msg.id === messageId);
    if (index !== -1) {
      this.state.messages.splice(index, 1);
      this.notifyStateUpdate();
      return true;
    }
    return false;
  }

  editMessage(messageId: string, newContent: string): boolean {
    const message = this.state.messages.find(msg => msg.id === messageId);
    if (message) {
      message.content = newContent;
      message.metadata = { ...message.metadata, edited: true };
      this.notifyStateUpdate();
      return true;
    }
    return false;
  }
}
```

#### React集成和状态管理
```typescript
// React Hook for conversation management
function useConversation(conversationId: string) {
  const [state, setState] = useState<ConversationState>({
    messages: [],
    conversationId,
    isStreaming: false,
    currentMessage: ''
  });

  const [manager] = useState(() => new StreamingConversationManager(conversationId));

  useEffect(() => {
    // 订阅状态更新
    const unsubscribe = manager.onStateUpdate((newState) => {
      setState(newState);
    });

    // 加载历史消息
    loadConversationHistory(conversationId).then(history => {
      if (history) {
        setState(prev => ({ ...prev, messages: history }));
      }
    });

    return unsubscribe;
  }, [conversationId, manager]);

  const sendMessage = useCallback(async (content: string) => {
    try {
      await manager.processStreamingMessage(content);
      // 保存到持久化存储
      await saveConversationHistory(conversationId, state.messages);
    } catch (error) {
      console.error('Failed to send message:', error);
    }
  }, [manager, conversationId, state.messages]);

  return {
    messages: state.messages,
    currentMessage: state.currentMessage,
    isStreaming: state.isStreaming,
    sendMessage,
    searchMessages: manager.searchMessages.bind(manager),
    deleteMessage: manager.deleteMessage.bind(manager),
    editMessage: manager.editMessage.bind(manager)
  };
}

// 高级消息管理功能
class AdvancedMessageManager {
  private conversationStore: Map<string, ConversationState> = new Map();

  // 消息压缩和优化
  compressConversation(conversationId: string, maxMessages: number = 20): boolean {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return false;

    if (conversation.messages.length <= maxMessages) return false;

    // 保留系统消息和最近的消息
    const systemMessages = conversation.messages.filter(msg => msg.role === 'system');
    const recentMessages = conversation.messages.slice(-maxMessages + systemMessages.length);

    // 创建摘要
    const oldMessages = conversation.messages.slice(0, -maxMessages + systemMessages.length);
    const summary = this.createConversationSummary(oldMessages);

    // 重建消息列表
    conversation.messages = [
      ...systemMessages,
      {
        id: `summary_${Date.now()}`,
        role: 'system' as const,
        content: `对话历史摘要: ${summary}`,
        timestamp: new Date()
      },
      ...recentMessages.filter(msg => msg.role !== 'system')
    ];

    return true;
  }

  private createConversationSummary(messages: ConversationState['messages']): string {
    // 简化的摘要生成逻辑
    const userMessages = messages.filter(msg => msg.role === 'user');
    const topics = userMessages.map(msg => this.extractTopic(msg.content));

    return `用户主要讨论了以下话题: ${topics.join(', ')}`;
  }

  // 消息分支管理
  createMessageBranch(
    conversationId: string,
    fromMessageId: string,
    newBranchId: string
  ): boolean {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return false;

    const messageIndex = conversation.messages.findIndex(msg => msg.id === fromMessageId);
    if (messageIndex === -1) return false;

    // 创建分支对话
    const branchMessages = conversation.messages.slice(0, messageIndex + 1);
    const branchConversation: ConversationState = {
      messages: [...branchMessages],
      conversationId: newBranchId,
      isStreaming: false,
      currentMessage: ''
    };

    this.conversationStore.set(newBranchId, branchConversation);
    return true;
  }

  // 消息导出和导入
  exportConversation(conversationId: string): string | null {
    const conversation = this.conversationStore.get(conversationId);
    if (!conversation) return null;

    return JSON.stringify({
      ...conversation,
      exportedAt: new Date().toISOString(),
      version: '1.0'
    });
  }

  importConversation(conversationData: string): string | null {
    try {
      const parsed = JSON.parse(conversationData);
      const conversationId = parsed.conversationId || `imported_${Date.now()}`;

      this.conversationStore.set(conversationId, {
        messages: parsed.messages || [],
        conversationId,
        isStreaming: false,
        currentMessage: ''
      });

      return conversationId;
    } catch (error) {
      console.error('Failed to import conversation:', error);
      return null;
    }
  }
}
```

#### 持久化存储方案
```typescript
// 浏览器存储适配器
class BrowserStorageAdapter {
  private storageKey = 'conversation_history';

  async saveConversation(conversationId: string, messages: any[]): Promise<void> {
    try {
      const stored = localStorage.getItem(this.storageKey);
      const conversations = stored ? JSON.parse(stored) : {};

      conversations[conversationId] = {
        messages,
        lastUpdated: new Date().toISOString()
      };

      localStorage.setItem(this.storageKey, JSON.stringify(conversations));
    } catch (error) {
      console.error('Failed to save conversation:', error);
    }
  }

  async loadConversation(conversationId: string): Promise<any[] | null> {
    try {
      const stored = localStorage.getItem(this.storageKey);
      if (!stored) return null;

      const conversations = JSON.parse(stored);
      return conversations[conversationId]?.messages || null;
    } catch (error) {
      console.error('Failed to load conversation:', error);
      return null;
    }
  }
}

// 服务端存储适配器
class ServerStorageAdapter {
  constructor(private apiBase: string) {}

  async saveConversation(conversationId: string, messages: any[]): Promise<void> {
    await fetch(`${this.apiBase}/conversations/${conversationId}`, {
      method: 'PUT',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ messages })
    });
  }

  async loadConversation(conversationId: string): Promise<any[] | null> {
    const response = await fetch(`${this.apiBase}/conversations/${conversationId}`);
    if (response.ok) {
      const data = await response.json();
      return data.messages;
    }
    return null;
  }
}
```

### 4. AG-UI - 组件化消息管理

AG-UI通过React组件状态和自定义Hook实现前端消息管理。

#### React组件状态管理
```typescript
interface MessageState {
  id: string;
  content: string;
  role: 'user' | 'assistant' | 'system';
  timestamp: Date;
  status: 'sending' | 'sent' | 'error';
  metadata?: {
    agentName?: string;
    toolCalls?: any[];
    reasoning?: string;
  };
}

interface ConversationComponentState {
  messages: MessageState[];
  isLoading: boolean;
  error: string | null;
  agentState: any;
  currentNode: string;
}

function ConversationManager() {
  const [state, setState] = useState<ConversationComponentState>({
    messages: [],
    isLoading: false,
    error: null,
    agentState: null,
    currentNode: ''
  });

  // 使用AG-UI的useCoAgent Hook
  const {
    state: agentState,
    nodeName,
    invoke
  } = useCoAgent<TravelAgentState>({
    name: "conversation_agent",
    initialState: INITIAL_STATE,

    // 实时监听智能体状态变化
    onChunk: (chunk) => {
      handleAgentChunk(chunk);
    },

    config: {
      streamSubgraphs: true,
      enableRealTimeUpdates: true
    }
  });

  const handleAgentChunk = useCallback((chunk: any) => {
    switch (chunk.type) {
      case 'agent-message':
        addMessage({
          content: chunk.content,
          role: 'assistant',
          metadata: {
            agentName: chunk.agentName,
            reasoning: chunk.reasoning
          }
        });
        break;

      case 'tool-call':
        addMessage({
          content: `正在调用工具: ${chunk.toolName}`,
          role: 'system',
          metadata: { toolCalls: [chunk] }
        });
        break;

      case 'error':
        setState(prev => ({
          ...prev,
          error: chunk.error,
          isLoading: false
        }));
        break;
    }
  }, []);

  const addMessage = useCallback((message: Omit<MessageState, 'id' | 'timestamp' | 'status'>) => {
    const newMessage: MessageState = {
      ...message,
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      timestamp: new Date(),
      status: 'sent'
    };

    setState(prev => ({
      ...prev,
      messages: [...prev.messages, newMessage]
    }));
  }, []);

  const sendMessage = useCallback(async (content: string) => {
    // 添加用户消息
    addMessage({ content, role: 'user' });

    setState(prev => ({ ...prev, isLoading: true, error: null }));

    try {
      await invoke({ userInput: content });
    } catch (error) {
      setState(prev => ({
        ...prev,
        error: error.message,
        isLoading: false
      }));
    }
  }, [invoke, addMessage]);

  return {
    messages: state.messages,
    isLoading: state.isLoading,
    error: state.error,
    agentState,
    currentNode: nodeName,
    sendMessage,
    addMessage
  };
}
```

#### 消息组件和虚拟化
```typescript
// 高性能消息列表组件
const MessageList = React.memo(({
  messages,
  isLoading
}: {
  messages: MessageState[];
  isLoading: boolean;
}) => {
  const listRef = useRef<HTMLDivElement>(null);

  // 虚拟化渲染优化
  const visibleMessages = useMemo(() => {
    // 只渲染可见的消息
    return messages.slice(-50); // 最近50条消息
  }, [messages]);

  // 自动滚动到底部
  useEffect(() => {
    if (listRef.current) {
      listRef.current.scrollTop = listRef.current.scrollHeight;
    }
  }, [messages]);

  return (
    <div ref={listRef} className="message-list">
      {visibleMessages.map((message) => (
        <MessageComponent
          key={message.id}
          message={message}
        />
      ))}

      {isLoading && (
        <div className="loading-indicator">
          <TypingIndicator />
        </div>
      )}
    </div>
  );
});

// 单个消息组件
const MessageComponent = React.memo(({ message }: { message: MessageState }) => {
  const [isExpanded, setIsExpanded] = useState(false);

  return (
    <div className={`message ${message.role}`}>
      <div className="message-header">
        <span className="role">{message.role}</span>
        {message.metadata?.agentName && (
          <span className="agent-name">{message.metadata.agentName}</span>
        )}
        <span className="timestamp">
          {message.timestamp.toLocaleTimeString()}
        </span>
      </div>

      <div className="message-content">
        {message.content}
      </div>

      {message.metadata?.reasoning && (
        <div className="message-metadata">
          <button
            onClick={() => setIsExpanded(!isExpanded)}
            className="expand-button"
          >
            {isExpanded ? '隐藏' : '显示'}推理过程
          </button>

          {isExpanded && (
            <div className="reasoning">
              {message.metadata.reasoning}
            </div>
          )}
        </div>
      )}

      {message.metadata?.toolCalls && (
        <div className="tool-calls">
          {message.metadata.toolCalls.map((call, index) => (
            <ToolCallComponent key={index} toolCall={call} />
          ))}
        </div>
      )}
    </div>
  );
});
```

#### 本地存储和同步
```typescript
// 浏览器存储Hook
function useConversationPersistence(conversationId: string) {
  const storageKey = `conversation_${conversationId}`;

  const saveToStorage = useCallback((messages: MessageState[]) => {
    try {
      const data = {
        messages,
        lastUpdated: new Date().toISOString(),
        version: '1.0'
      };
      localStorage.setItem(storageKey, JSON.stringify(data));
    } catch (error) {
      console.error('Failed to save conversation:', error);
    }
  }, [storageKey]);

  const loadFromStorage = useCallback((): MessageState[] | null => {
    try {
      const stored = localStorage.getItem(storageKey);
      if (!stored) return null;

      const data = JSON.parse(stored);
      return data.messages || null;
    } catch (error) {
      console.error('Failed to load conversation:', error);
      return null;
    }
  }, [storageKey]);

  const clearStorage = useCallback(() => {
    localStorage.removeItem(storageKey);
  }, [storageKey]);

  return { saveToStorage, loadFromStorage, clearStorage };
}

// 自动保存Hook
function useAutoSave(
  messages: MessageState[],
  conversationId: string,
  debounceMs: number = 1000
) {
  const { saveToStorage } = useConversationPersistence(conversationId);

  const debouncedSave = useMemo(
    () => debounce(saveToStorage, debounceMs),
    [saveToStorage, debounceMs]
  );

  useEffect(() => {
    if (messages.length > 0) {
      debouncedSave(messages);
    }
  }, [messages, debouncedSave]);

  // 清理函数
  useEffect(() => {
    return () => {
      debouncedSave.cancel();
    };
  }, [debouncedSave]);
}
```

## 性能优化策略对比

### 1. 内存管理
- **LangGraph**: 自动状态压缩 + 检查点卸载
- **ADK**: 静态指令缓存 + 会话分片
- **Vercel AI SDK**: 流式传输 + 客户端缓存
- **AG-UI**: 虚拟化渲染 + 懒加载

### 2. 存储优化
- **LangGraph**: SQLite/PostgreSQL检查点
- **ADK**: 序列化状态 + 增量更新
- **Vercel AI SDK**: 自定义存储适配器
- **AG-UI**: 浏览器存储 + 压缩

### 3. 网络优化
- **LangGraph**: 状态差分传输
- **ADK**: 事件驱动更新
- **Vercel AI SDK**: 流式传输 + 断点续传
- **AG-UI**: WebSocket实时同步

## 最佳实践建议

### 1. 选择合适的存储策略
```python
# 根据场景选择存储方案
if conversation_length > 1000:
    # 长对话：使用压缩和摘要
    use_conversation_compression()
elif real_time_requirements:
    # 实时场景：使用流式状态
    use_streaming_state()
elif enterprise_compliance:
    # 企业场景：使用加密存储
    use_encrypted_persistence()
```

### 2. 实现智能上下文管理
```python
def optimize_context_window(messages, max_tokens=4000):
    """智能优化上下文窗口"""

    # 策略1: 保留关键消息
    key_messages = extract_key_messages(messages)

    # 策略2: 创建对话摘要
    if calculate_tokens(messages) > max_tokens:
        summary = create_summary(messages[:-10])
        return [summary] + messages[-10:]

    return messages
```

### 3. 实现多级缓存策略
```typescript
// 多级缓存实现
class MessageCacheManager {
  private memoryCache = new Map();
  private diskCache = new LocalStorageCache();
  private serverCache = new ServerCache();

  async getMessage(id: string) {
    // L1: 内存缓存
    if (this.memoryCache.has(id)) {
      return this.memoryCache.get(id);
    }

    // L2: 本地存储
    const diskResult = await this.diskCache.get(id);
    if (diskResult) {
      this.memoryCache.set(id, diskResult);
      return diskResult;
    }

    // L3: 服务器缓存
    const serverResult = await this.serverCache.get(id);
    if (serverResult) {
      this.diskCache.set(id, serverResult);
      this.memoryCache.set(id, serverResult);
      return serverResult;
    }

    return null;
  }
}
```

## 总结

各框架的消息历史管理能力排序：

1. **LangGraph** - 最完善的自动化消息管理，检查点机制强大
2. **ADK** - 企业级会话管理，智能体继承机制优秀
3. **Vercel AI SDK** - 流式处理优秀，适合实时应用
4. **AG-UI** - 前端体验最佳，组件化程度高

**选择建议**：
- **复杂对话系统**: 选择LangGraph的自动化管理
- **企业级应用**: 选择ADK的会话状态机制
- **实时交互应用**: 选择Vercel AI SDK的流式处理
- **用户界面重点**: 选择AG-UI的组件化方案

关键成功因素：
- 🎯 **合适的存储策略** - 根据数据量和访问模式选择
- ⚡ **性能优化** - 实现多级缓存和智能压缩
- 🔄 **状态一致性** - 确保多智能体间状态同步
- 📊 **监控和调试** - 提供完整的消息追踪能力
