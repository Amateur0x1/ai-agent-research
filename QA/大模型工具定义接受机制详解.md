# 大模型工具定义接受机制详解

## Q: 大模型的对接，本身就接受 tools 定义是吧，然后大模型就会根据定义返回 tool call 的 json 是嘛？

### 简短回答

**是的，完全正确！** 

现代支持 Function Calling 的大模型（如 GPT-4、Claude-3.5、Gemini 等）在 API 层面原生支持 `tools` 参数，模型会根据我们提供的工具定义，智能决策是否需要调用工具，并返回标准格式的 tool call JSON。

### 详细机制解析

#### 1. API 原生支持

**所有主流 LLM API 都有 `tools` 参数**：

**OpenAI API**：
```python
import openai

response = openai.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "分析数据"}],
    tools=[  # 原生支持的参数
        {
            "type": "function",
            "function": {
                "name": "execute_code", 
                "description": "执行Python代码",
                "parameters": {...}
            }
        }
    ],
    tool_choice="auto"  # 让模型自主决定
)
```

**Anthropic Claude API**：
```python
import anthropic

response = anthropic.messages.create(
    model="claude-3-5-sonnet-20241022",
    messages=[{"role": "user", "content": "分析数据"}],
    tools=[  # 同样原生支持
        {
            "name": "execute_code",
            "description": "执行Python代码", 
            "input_schema": {...}
        }
    ]
)
```

**Google Gemini API**：
```python
import google.generativeai as genai

response = genai.chat(
    messages=[{"role": "user", "content": "分析数据"}],
    tools=[  # 原生支持
        {
            "function_declarations": [
                {
                    "name": "execute_code",
                    "description": "执行Python代码",
                    "parameters": {...}
                }
            ]
        }
    ]
)
```

#### 2. 模型的内在机制

**模型是如何"理解"工具定义的？**

实际上，模型在训练时就学习了如何：
1. **解析工具定义**：理解每个工具的功能和参数
2. **情景匹配**：判断当前对话是否需要使用某个工具
3. **参数生成**：根据上下文生成合适的工具调用参数
4. **格式输出**：按照标准格式输出 tool call JSON

**这不是后处理，而是模型的核心能力之一**。

#### 3. MathModelAgent 中的实际使用

**通过 LiteLLM 统一接口**：
```python
# app/core/llm/llm.py
import litellm

class LLM:
    async def chat(self, history: list, tools: list = None, tool_choice: str = "auto"):
        response = await litellm.achat(
            model=self.model,           # 可以是 gpt-4o, claude-3-5-sonnet 等
            messages=history,
            tools=tools,                # 直接传递工具定义
            tool_choice=tool_choice,    # 工具选择策略
            api_key=self.api_key,
            base_url=self.base_url
        )
        return response
```

**工具定义示例**：
```python
# app/core/functions.py
coder_tools = [
    {
        "type": "function",  # OpenAI 格式
        "function": {
            "name": "execute_code",
            "description": "执行Python代码并返回结果，可以进行数据分析、可视化、数学建模等操作",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "要执行的Python代码，支持pandas、numpy、matplotlib等库"
                    }
                },
                "required": ["code"]
            }
        }
    }
]
```

**模型的返回**：
```json
{
    "id": "chatcmpl-...",
    "object": "chat.completion",
    "choices": [
        {
            "message": {
                "role": "assistant",
                "content": null,
                "tool_calls": [  // 模型根据工具定义生成的
                    {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                            "name": "execute_code",  // 匹配我们定义的工具名
                            "arguments": "{\"code\": \"import pandas as pd\\ndf = pd.read_csv('data.csv')\\nprint(df.describe())\"}"
                        }
                    }
                ]
            }
        }
    ]
}
```

#### 4. 不同模型的格式差异

虽然都支持工具调用，但格式稍有不同：

**OpenAI 格式**：
```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "execute_code",
            "parameters": {"type": "object", "properties": {...}}
        }
    }
]
```

**Claude 格式**：
```python
tools = [
    {
        "name": "execute_code", 
        "description": "执行代码",
        "input_schema": {"type": "object", "properties": {...}}
    }
]
```

**LiteLLM 的作用**：
```python
# LiteLLM 自动处理格式转换
response = await litellm.achat(
    model="gpt-4o",        # 自动使用 OpenAI 格式
    # 或
    model="claude-3-5-sonnet",  # 自动转换为 Claude 格式
    tools=unified_tools    # 统一的工具定义
)
```

#### 5. 模型决策的智能性

**模型会根据多种因素决定是否调用工具**：

```python
# 示例对话
messages = [
    {"role": "system", "content": "你是数学建模专家"},
    {"role": "user", "content": "请分析附件中的数据"}  # 暗示需要数据处理
]

# 模型会判断：
# 1. 用户要求分析数据 → 可能需要 execute_code
# 2. 当前没有数据在内存中 → 需要先加载数据  
# 3. 生成合适的代码来完成任务
```

**模型可能的响应**：
```json
{
    "tool_calls": [
        {
            "function": {
                "name": "execute_code",
                "arguments": "{\"code\": \"import pandas as pd\\nimport os\\n\\n# 查看当前目录的文件\\nfiles = os.listdir('.')\\ndata_files = [f for f in files if f.endswith(('.csv', '.xlsx', '.json'))]\\nprint('发现数据文件:', data_files)\"}"
            }
        }
    ]
}
```

#### 6. 工具选择策略

**tool_choice 参数控制**：

```python
# 1. 自动选择 (推荐)
tool_choice="auto"  # 模型智能决定是否使用工具

# 2. 强制使用工具
tool_choice="required"  # 模型必须调用某个工具

# 3. 禁用工具
tool_choice="none"  # 模型不能使用任何工具

# 4. 指定特定工具
tool_choice={
    "type": "function",
    "function": {"name": "execute_code"}
}  # 模型必须使用 execute_code
```

#### 7. 实际运行示例

**完整的调用流程**：
```python
# MathModelAgent 实际运行
async def demo_tool_calling():
    # 1. 准备工具定义
    tools = [
        {
            "type": "function",
            "function": {
                "name": "execute_code",
                "description": "执行Python代码",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "code": {"type": "string", "description": "Python代码"}
                    },
                    "required": ["code"]
                }
            }
        }
    ]
    
    # 2. 发送给模型
    response = await litellm.achat(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": "请计算 1 到 100 的平方和"}
        ],
        tools=tools,
        tool_choice="auto"
    )
    
    # 3. 模型的响应
    print("模型响应:", response.choices[0].message)
    
    # 可能的输出：
    # {
    #     "role": "assistant",
    #     "tool_calls": [
    #         {
    #             "function": {
    #                 "name": "execute_code", 
    #                 "arguments": '{"code": "sum(i**2 for i in range(1, 101))"}'
    #             }
    #         }
    #     ]
    # }
```

#### 8. 常见问题解答

**Q: 模型是怎么知道要生成 tool call 的？**
A: 模型在训练时学习了大量的工具调用示例，知道什么情况下需要外部工具帮助。

**Q: 模型会自己编造工具吗？**  
A: 不会，模型只会使用我们在 `tools` 参数中明确定义的工具。

**Q: 所有模型都支持吗？**
A: 不是，只有专门训练过 Function Calling 的模型才支持，如：
- GPT-4/GPT-4o (OpenAI)
- Claude-3/3.5 (Anthropic)  
- Gemini Pro (Google)
- 某些开源模型 (如 Llama-3.1-Tool-Use)

**Q: 工具定义写得不好会怎样？**
A: 模型可能无法理解工具用途，或者生成错误的参数。好的描述很重要。

#### 9. 最佳实践

**工具定义的最佳实践**：
```python
{
    "type": "function",
    "function": {
        "name": "execute_code",  # 简洁明确的名称
        "description": "执行Python代码进行数据分析、可视化和数学建模。支持pandas、numpy、matplotlib、scikit-learn等常用库。代码执行在Jupyter环境中，可以保存变量状态。",  # 详细但精确的描述
        "parameters": {
            "type": "object", 
            "properties": {
                "code": {
                    "type": "string",
                    "description": "要执行的Python代码。请确保代码格式正确，包含必要的import语句。"
                }
            },
            "required": ["code"]
        }
    }
}
```

### 总结

你的理解完全正确：

1. **大模型 API 原生支持 `tools` 参数**
2. **模型根据工具定义智能决策是否调用工具**  
3. **模型按标准格式返回 tool call JSON**
4. **我们的代码解析 JSON 并执行实际函数**
5. **执行结果返回给模型继续对话**

这是现代 LLM 的标准能力，不需要额外的框架或处理，**模型本身就"懂"工具调用**！

MathModelAgent 正是基于这个机制，通过 LiteLLM 统一了不同模型的接口，实现了跨模型的工具调用能力。